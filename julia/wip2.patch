diff --git a/Make.inc b/Make.inc
index c8ed2e07e..49dc93c0b 100644
--- a/Make.inc
+++ b/Make.inc
@@ -514,11 +514,11 @@ SHIPFLAGS := -O3 -ggdb2 -falign-functions
 endif
 
 ifeq ($(USEMSVC),1)
-CC := compile cl
-CXX := compile cl
+CC := compile clang-cl
+CXX := compile clang-cl
 DEBUGFLAGS := -O0 -Z7 -DJL_DEBUG_BUILD -Gy
 SHIPFLAGS := -O2 -Z7
-JCFLAGS := -std:c11 -D_FILE_OFFSET_BITS=64
+JCFLAGS := -std:c11 -experimental:c11atomics -D_FILE_OFFSET_BITS=64
 JCXXFLAGS := -GR-
 endif
 
@@ -579,11 +579,11 @@ endif
 
 JFFLAGS := -O2 $(fPIC)
 CPP := $(CC) -E
-AR := $(CROSS_COMPILE)ar
-AS := $(CROSS_COMPILE)as
-LD := $(CROSS_COMPILE)ld
-RANLIB := $(CROSS_COMPILE)ranlib
-OBJCOPY := $(CROSS_COMPILE)objcopy
+AR := llvm-ar
+AS := clang
+LD := lld-link
+RANLIB := llvm-ranlib
+OBJCOPY := llvm-objcopy
 
 CPP_STDOUT := $(CPP) -P
 
@@ -932,9 +932,9 @@ endif
 
 # Set MARCH-specific flags
 ifneq ($(MARCH),)
-CC += -march=$(MARCH)
-CXX += -march=$(MARCH)
-FC += -march=$(MARCH)
+#CC += -march=$(MARCH)
+#CXX += -march=$(MARCH)
+#FC += -march=$(MARCH)
 JULIA_CPU_TARGET ?= $(MARCH)
 endif
 
@@ -985,8 +985,8 @@ endif
 ifeq ($(OS),WINNT)
 ifneq ($(ARCH),x86_64)
 ifneq ($(USECLANG),1)
-JCFLAGS += -mincoming-stack-boundary=2
-JCXXFLAGS += -mincoming-stack-boundary=2
+#JCFLAGS += -mincoming-stack-boundary=2
+#JCXXFLAGS += -mincoming-stack-boundary=2
 endif
 endif
 endif
@@ -1160,7 +1160,7 @@ endif
 
 # BinaryBuilder options.  We default to "on" for all the projects listed in BB_PROJECTS,
 # but only if contrib/normalize_triplet.py works for our requested triplet.
-ifeq ($(shell $(call invoke_python,$(JULIAHOME)/contrib/normalize_triplet.py) $(or $(XC_HOST),$(XC_HOST),$(BUILD_MACHINE)) >/dev/null 2>/dev/null; echo $$?),0)
+ifeq (0 ,0)
 USE_BINARYBUILDER ?= 1
 else
 ifneq ($(shell $(call invoke_python,$(JULIAHOME)/contrib/normalize_triplet.py) x86_64-linux-gnu),x86_64-linux-gnu)
@@ -1172,7 +1172,7 @@ endif
 # Auto-detect triplet once, create different versions that we use as defaults below for each BB install target
 FC_VERSION := $(shell $(FC) --version 2>/dev/null | head -1)
 FC_OR_CC_VERSION := $(or $(FC_VERSION),$(shell $(CC) --version 2>/dev/null | head -1))
-BB_TRIPLET_LIBGFORTRAN_CXXABI := $(shell $(call invoke_python,$(JULIAHOME)/contrib/normalize_triplet.py) $(or $(XC_HOST),$(XC_HOST),$(BUILD_MACHINE)) "$(FC_OR_CC_VERSION)" "$(or $(shell echo '\#include <string>' | $(CXX) $(CXXFLAGS) -TP -E - | grep _GLIBCXX_USE_CXX11_ABI | awk '{ print $$3 }' ),1)")
+BB_TRIPLET_LIBGFORTRAN_CXXABI := x86_64-pc-windows-msvc
 BB_TRIPLET_LIBGFORTRAN := $(subst $(SPACE),-,$(filter-out cxx%,$(subst -,$(SPACE),$(BB_TRIPLET_LIBGFORTRAN_CXXABI))))
 BB_TRIPLET_CXXABI := $(subst $(SPACE),-,$(filter-out libgfortran%,$(subst -,$(SPACE),$(BB_TRIPLET_LIBGFORTRAN_CXXABI))))
 BB_TRIPLET := $(subst $(SPACE),-,$(filter-out cxx%,$(filter-out libgfortran%,$(subst -,$(SPACE),$(BB_TRIPLET_LIBGFORTRAN_CXXABI)))))
@@ -1337,8 +1337,9 @@ endif
 ifeq ($(OS), WINNT)
 HAVE_SSP := 1
 OSLIBS += -Wl,--export-all-symbols -Wl,--version-script=$(JULIAHOME)/src/julia.expmap \
-	$(NO_WHOLE_ARCHIVE) -lpsapi -lkernel32 -lws2_32 -liphlpapi -lwinmm -ldbghelp -luserenv -lsecur32 -latomic
-JLDFLAGS += -Wl,--stack,8388608
+	$(NO_WHOLE_ARCHIVE) -lpsapi -lkernel32 -lws2_32 -liphlpapi -lwinmm -ldbghelp -luserenv -lsecur32 
+#  -latomic
+# JLDFLAGS += -Wl,--stack,8388608
 ifeq ($(ARCH),i686)
 JLDFLAGS += -Wl,--large-address-aware
 endif
@@ -1639,9 +1640,9 @@ endif
 WARNCOLOR:="\033[33;1m"
 ENDCOLOR:="\033[0m"
 
-ifeq ($(VERBOSE), 1)
+ifeq ($(VERBOSE), 0)
 
-QUIET_MAKE = -v
+# QUIET_MAKE = -v
 
 CCCOLOR:="\033[34m"
 LINKCOLOR:="\033[34;1m"
diff --git a/deps/libgit2.mk b/deps/libgit2.mk
index 30d94aeca..3e4d0feeb 100644
--- a/deps/libgit2.mk
+++ b/deps/libgit2.mk
@@ -18,7 +18,7 @@ ifeq ($(OS),WINNT)
 LIBGIT2_OPTS += -DWIN32=ON -DMINGW=ON
 ifneq ($(ARCH),x86_64)
 ifneq ($(USECLANG),1)
-LIBGIT2_OPTS += -DCMAKE_C_FLAGS="-mincoming-stack-boundary=2"
+#LIBGIT2_OPTS += -DCMAKE_C_FLAGS="-mincoming-stack-boundary=2"
 endif
 endif
 ifeq ($(BUILD_OS),WINNT)
diff --git a/src/Makefile b/src/Makefile
index 2955e2b9b..0276eb8f9 100644
--- a/src/Makefile
+++ b/src/Makefile
@@ -23,7 +23,7 @@ FLAGS := \
 ifeq ($(USEGCC),1) # GCC bug #25509 (void)__attribute__((warn_unused_result))
 FLAGS += -Wno-unused-result
 endif
-JCFLAGS += -Wold-style-definition -Wstrict-prototypes -Wc++-compat
+#JCFLAGS += -Wold-style-definition -Wstrict-prototypes -Wc++-compat
 
 ifeq ($(USECLANG),1)
 FLAGS += -Wno-return-type-c-linkage
@@ -108,7 +108,7 @@ PUBLIC_HEADERS += $(addprefix $(SRCDIR)/,julia_gcext.h)
 PUBLIC_HEADER_TARGETS := $(addprefix $(build_includedir)/julia/,$(notdir $(PUBLIC_HEADERS)) $(UV_HEADERS))
 
 LLVM_LDFLAGS := $(shell $(LLVM_CONFIG_HOST) --ldflags)
-LLVM_CXXFLAGS := $(shell $(LLVM_CONFIG_HOST) --cxxflags)
+LLVM_CXXFLAGS := $(subst /,-,$(shell $(LLVM_CONFIG_HOST) --cxxflags))
 
 # llvm-config --cxxflags does not return -DNDEBUG
 ifeq ($(shell $(LLVM_CONFIG_HOST) --assertion-mode),OFF)
diff --git a/src/array.c b/src/array.c
index 0b5822967..2c1eff03f 100644
--- a/src/array.c
+++ b/src/array.c
@@ -549,7 +549,7 @@ JL_DLLEXPORT jl_value_t *jl_ptrarrayref(jl_array_t *a JL_PROPAGATES_ROOT, size_t
 {
     assert(i < jl_array_len(a));
     assert(a->flags.ptrarray);
-    jl_value_t *elt = jl_atomic_load_relaxed(((_Atomic(jl_value_t*)*)a->data) + i);
+    jl_value_t *elt = jl_atomic_load_relaxed(((_JAtomic(jl_value_t*)*)a->data) + i);
     if (elt == NULL)
         jl_throw(jl_undefref_exception);
     return elt;
@@ -578,7 +578,7 @@ JL_DLLEXPORT jl_value_t *jl_arrayref(jl_array_t *a, size_t i)
 JL_DLLEXPORT int jl_array_isassigned(jl_array_t *a, size_t i)
 {
     if (a->flags.ptrarray) {
-        return jl_atomic_load_relaxed(((_Atomic(jl_value_t*)*)jl_array_data(a)) + i) != NULL;
+        return jl_atomic_load_relaxed(((_JAtomic(jl_value_t*)*)jl_array_data(a)) + i) != NULL;
     }
     else if (a->flags.hasptr) {
          jl_datatype_t *eltype = (jl_datatype_t*)jl_tparam0(jl_typeof(a));
@@ -617,7 +617,7 @@ JL_DLLEXPORT void jl_arrayset(jl_array_t *a JL_ROOTING_ARGUMENT, jl_value_t *rhs
         arrayassign_safe(hasptr, jl_array_owner(a), &((char*)a->data)[i * a->elsize], rhs, a->elsize);
     }
     else {
-        jl_atomic_store_release(((_Atomic(jl_value_t*)*)a->data) + i, rhs);
+        jl_atomic_store_release(((_JAtomic(jl_value_t*)*)a->data) + i, rhs);
         jl_gc_wb(jl_array_owner(a), rhs);
     }
 }
@@ -627,7 +627,7 @@ JL_DLLEXPORT void jl_arrayunset(jl_array_t *a, size_t i)
     if (i >= jl_array_len(a))
         jl_bounds_error_int((jl_value_t*)a, i + 1);
     if (a->flags.ptrarray)
-        jl_atomic_store_relaxed(((_Atomic(jl_value_t*)*)a->data) + i, NULL);
+        jl_atomic_store_relaxed(((_JAtomic(jl_value_t*)*)a->data) + i, NULL);
     else if (a->flags.hasptr) {
         size_t elsize = a->elsize;
         jl_assume(elsize >= sizeof(void*) && elsize % sizeof(void*) == 0);
@@ -1194,8 +1194,8 @@ static NOINLINE ssize_t jl_array_ptr_copy_forward(jl_value_t *owner,
                                                   void **src_p, void **dest_p,
                                                   ssize_t n) JL_NOTSAFEPOINT
 {
-    _Atomic(void*) *src_pa = (_Atomic(void*)*)src_p;
-    _Atomic(void*) *dest_pa = (_Atomic(void*)*)dest_p;
+    _JAtomic(void*) *src_pa = (_JAtomic(void*)*)src_p;
+    _JAtomic(void*) *dest_pa = (_JAtomic(void*)*)dest_p;
     for (ssize_t i = 0; i < n; i++) {
         void *val = jl_atomic_load_relaxed(src_pa + i);
         jl_atomic_store_release(dest_pa + i, val);
@@ -1212,8 +1212,8 @@ static NOINLINE ssize_t jl_array_ptr_copy_backward(jl_value_t *owner,
                                                    void **src_p, void **dest_p,
                                                    ssize_t n) JL_NOTSAFEPOINT
 {
-    _Atomic(void*) *src_pa = (_Atomic(void*)*)src_p;
-    _Atomic(void*) *dest_pa = (_Atomic(void*)*)dest_p;
+    _JAtomic(void*) *src_pa = (_JAtomic(void*)*)src_p;
+    _JAtomic(void*) *dest_pa = (_JAtomic(void*)*)dest_p;
     for (ssize_t i = 0; i < n; i++) {
         void *val = jl_atomic_load_relaxed(src_pa + n - i - 1);
         jl_atomic_store_release(dest_pa + n - i - 1, val);
diff --git a/src/cgmemmgr.cpp b/src/cgmemmgr.cpp
index 9f4d69137..48a24eb9e 100644
--- a/src/cgmemmgr.cpp
+++ b/src/cgmemmgr.cpp
@@ -213,7 +213,7 @@ static intptr_t get_anon_hdl(void)
     return -1;
 }
 
-static _Atomic(size_t) map_offset{0};
+static _JAtomic(size_t) map_offset{0};
 // Multiple of 128MB.
 // Hopefully no one will set a ulimit for this to be a problem...
 static constexpr size_t map_size_inc_default = 128 * 1024 * 1024;
diff --git a/src/cgutils.cpp b/src/cgutils.cpp
index c091111f3..92205bc60 100644
--- a/src/cgutils.cpp
+++ b/src/cgutils.cpp
@@ -224,14 +224,21 @@ void jl_debugcache_t::initialize(Module *m) {
         julia_h,
         71, // At the time of this writing. Not sure if it's worth it to keep this in sync
         0 * 8, // sizeof(jl_value_t) * 8,
+#ifdef _MSC_VER
+        alignof(void*) * 8, // __alignof__(jl_value_t) * 8,
+#else
         __alignof__(void*) * 8, // __alignof__(jl_value_t) * 8,
+#endif
         DINode::FlagZero, // Flags
         nullptr,    // Derived from
         nullptr);  // Elements - will be corrected later
 
     jl_pvalue_dillvmt = dbuilder.createPointerType(jl_value_dillvmt, sizeof(jl_value_t*) * 8,
+#ifdef _MSC_VER
+                                                alignof(jl_value_t*) * 8);
+#else
                                                 __alignof__(jl_value_t*) * 8);
-
+#endif
     SmallVector<llvm::Metadata *, 1> Elts;
     std::vector<Metadata*> diargs(0);
     Elts.push_back(jl_pvalue_dillvmt);
@@ -239,8 +246,11 @@ void jl_debugcache_t::initialize(Module *m) {
     dbuilder.getOrCreateArray(Elts));
 
     jl_ppvalue_dillvmt = dbuilder.createPointerType(jl_pvalue_dillvmt, sizeof(jl_value_t**) * 8,
+#ifdef _MSC_VER
+                                                    alignof(jl_value_t**) * 8);
+#else
                                                     __alignof__(jl_value_t**) * 8);
-
+#endif
     diargs.push_back(jl_pvalue_dillvmt);    // Return Type (ret value)
     diargs.push_back(jl_pvalue_dillvmt);    // First Argument (function)
     diargs.push_back(jl_ppvalue_dillvmt);   // Second Argument (argv)
diff --git a/src/codegen.cpp b/src/codegen.cpp
index 462e9c0fb..e07b97444 100644
--- a/src/codegen.cpp
+++ b/src/codegen.cpp
@@ -4464,11 +4464,13 @@ static Value *global_binding_pointer(jl_codectx_t &ctx, jl_module_t *m, jl_sym_t
     }
     if (assign) {
         if (b->owner != m) {
-            char *msg;
-            (void)asprintf(&msg, "cannot assign a value to imported variable %s.%s from module %s",
-                    jl_symbol_name(b->owner->name), jl_symbol_name(s), jl_symbol_name(m->name));
+            std::string msg = "cannot assign a value to imported variable "
+                        + std::string(jl_symbol_name(b->owner->name)) 
+                        + "."
+                        + std::string(jl_symbol_name(s))
+                        + " from module "
+                        + std::string(jl_symbol_name(m->name));
             emit_error(ctx, msg);
-            free(msg);
             return NULL;
         }
     }
@@ -8966,7 +8968,7 @@ extern "C" JL_DLLEXPORT jl_value_t *jl_get_libllvm_impl(void) JL_NOTSAFEPOINT
 {
 #if defined(_OS_WINDOWS_)
     HMODULE mod;
-    if (!GetModuleHandleEx(GET_MODULE_HANDLE_EX_FLAG_FROM_ADDRESS, (LPCSTR)&llvm::DebugFlag, &mod))
+    if (!GetModuleHandleExA(GET_MODULE_HANDLE_EX_FLAG_FROM_ADDRESS, (LPCSTR)&llvm::DebugFlag, &mod))
         return jl_nothing;
     wchar_t path16[MAX_PATH];
     DWORD n16 = GetModuleFileNameW(mod, path16, MAX_PATH);
diff --git a/src/datatype.c b/src/datatype.c
index 1cf83f5e2..b01c3937b 100644
--- a/src/datatype.c
+++ b/src/datatype.c
@@ -938,34 +938,34 @@ JL_DLLEXPORT jl_value_t *jl_atomic_new_bits(jl_value_t *dt, const char *data)
     size_t nb = jl_datatype_size(bt);
     // some types have special pools to minimize allocations
     if (nb == 0)               return jl_new_struct_uninit(bt); // returns bt->instance
-    if (bt == jl_bool_type)    return (1 & jl_atomic_load((_Atomic(int8_t)*)data)) ? jl_true : jl_false;
-    if (bt == jl_uint8_type)   return jl_box_uint8(jl_atomic_load((_Atomic(uint8_t)*)data));
-    if (bt == jl_int64_type)   return jl_box_int64(jl_atomic_load((_Atomic(int64_t)*)data));
-    if (bt == jl_int32_type)   return jl_box_int32(jl_atomic_load((_Atomic(int32_t)*)data));
-    if (bt == jl_int8_type)    return jl_box_int8(jl_atomic_load((_Atomic(int8_t)*)data));
-    if (bt == jl_int16_type)   return jl_box_int16(jl_atomic_load((_Atomic(int16_t)*)data));
-    if (bt == jl_uint64_type)  return jl_box_uint64(jl_atomic_load((_Atomic(uint64_t)*)data));
-    if (bt == jl_uint32_type)  return jl_box_uint32(jl_atomic_load((_Atomic(uint32_t)*)data));
-    if (bt == jl_uint16_type)  return jl_box_uint16(jl_atomic_load((_Atomic(uint16_t)*)data));
-    if (bt == jl_char_type)    return jl_box_char(jl_atomic_load((_Atomic(uint32_t)*)data));
+    if (bt == jl_bool_type)    return (1 & jl_atomic_load((_JAtomic(int8_t)*)data)) ? jl_true : jl_false;
+    if (bt == jl_uint8_type)   return jl_box_uint8(jl_atomic_load((_JAtomic(uint8_t)*)data));
+    if (bt == jl_int64_type)   return jl_box_int64(jl_atomic_load((_JAtomic(int64_t)*)data));
+    if (bt == jl_int32_type)   return jl_box_int32(jl_atomic_load((_JAtomic(int32_t)*)data));
+    if (bt == jl_int8_type)    return jl_box_int8(jl_atomic_load((_JAtomic(int8_t)*)data));
+    if (bt == jl_int16_type)   return jl_box_int16(jl_atomic_load((_JAtomic(int16_t)*)data));
+    if (bt == jl_uint64_type)  return jl_box_uint64(jl_atomic_load((_JAtomic(uint64_t)*)data));
+    if (bt == jl_uint32_type)  return jl_box_uint32(jl_atomic_load((_JAtomic(uint32_t)*)data));
+    if (bt == jl_uint16_type)  return jl_box_uint16(jl_atomic_load((_JAtomic(uint16_t)*)data));
+    if (bt == jl_char_type)    return jl_box_char(jl_atomic_load((_JAtomic(uint32_t)*)data));
 
     jl_task_t *ct = jl_current_task;
     jl_value_t *v = jl_gc_alloc(ct->ptls, nb, bt);
     // data is aligned to the power of two,
     // we will write too much of v, but the padding should exist
     if (nb == 1)
-        *(uint8_t*) v = jl_atomic_load((_Atomic(uint8_t)*)data);
+        *(uint8_t*) v = jl_atomic_load((_JAtomic(uint8_t)*)data);
     else if (nb <= 2)
-        *(uint16_t*)v = jl_atomic_load((_Atomic(uint16_t)*)data);
+        *(uint16_t*)v = jl_atomic_load((_JAtomic(uint16_t)*)data);
     else if (nb <= 4)
-        *(uint32_t*)v = jl_atomic_load((_Atomic(uint32_t)*)data);
+        *(uint32_t*)v = jl_atomic_load((_JAtomic(uint32_t)*)data);
 #if MAX_POINTERATOMIC_SIZE >= 8
     else if (nb <= 8)
-        *(uint64_t*)v = jl_atomic_load((_Atomic(uint64_t)*)data);
+        *(uint64_t*)v = jl_atomic_load((_JAtomic(uint64_t)*)data);
 #endif
 #if MAX_POINTERATOMIC_SIZE >= 16
     else if (nb <= 16)
-        *(jl_uint128_t*)v = jl_atomic_load((_Atomic(jl_uint128_t)*)data);
+        *(jl_uint128_t*)v = jl_atomic_load((_JAtomic(jl_uint128_t)*)data);
 #endif
     else
         abort();
@@ -981,18 +981,18 @@ JL_DLLEXPORT void jl_atomic_store_bits(char *dst, const jl_value_t *src, int nb)
     if (nb == 0)
         ;
     else if (nb == 1)
-        jl_atomic_store((_Atomic(uint8_t)*)dst, *(uint8_t*)src);
+        jl_atomic_store((_JAtomic(uint8_t)*)dst, *(uint8_t*)src);
     else if (nb == 2)
-        jl_atomic_store((_Atomic(uint16_t)*)dst, *(uint16_t*)src);
+        jl_atomic_store((_JAtomic(uint16_t)*)dst, *(uint16_t*)src);
     else if (nb <= 4)
-        jl_atomic_store((_Atomic(uint32_t)*)dst, zext_read32(src, nb));
+        jl_atomic_store((_JAtomic(uint32_t)*)dst, zext_read32(src, nb));
 #if MAX_POINTERATOMIC_SIZE >= 8
     else if (nb <= 8)
-        jl_atomic_store((_Atomic(uint64_t)*)dst, zext_read64(src, nb));
+        jl_atomic_store((_JAtomic(uint64_t)*)dst, zext_read64(src, nb));
 #endif
 #if MAX_POINTERATOMIC_SIZE >= 16
     else if (nb <= 16)
-        jl_atomic_store((_Atomic(jl_uint128_t)*)dst, zext_read128(src, nb));
+        jl_atomic_store((_JAtomic(jl_uint128_t)*)dst, zext_read128(src, nb));
 #endif
     else
         abort();
@@ -1005,32 +1005,32 @@ JL_DLLEXPORT jl_value_t *jl_atomic_swap_bits(jl_value_t *dt, char *dst, const jl
     jl_datatype_t *bt = (jl_datatype_t*)dt;
     // some types have special pools to minimize allocations
     if (nb == 0)               return jl_new_struct_uninit(bt); // returns bt->instance
-    if (bt == jl_bool_type)    return (1 & jl_atomic_exchange((_Atomic(int8_t)*)dst, 1 & *(int8_t*)src)) ? jl_true : jl_false;
-    if (bt == jl_uint8_type)   return jl_box_uint8(jl_atomic_exchange((_Atomic(uint8_t)*)dst, *(int8_t*)src));
-    if (bt == jl_int64_type)   return jl_box_int64(jl_atomic_exchange((_Atomic(int64_t)*)dst, *(int64_t*)src));
-    if (bt == jl_int32_type)   return jl_box_int32(jl_atomic_exchange((_Atomic(int32_t)*)dst, *(int32_t*)src));
-    if (bt == jl_int8_type)    return jl_box_int8(jl_atomic_exchange((_Atomic(int8_t)*)dst, *(int8_t*)src));
-    if (bt == jl_int16_type)   return jl_box_int16(jl_atomic_exchange((_Atomic(int16_t)*)dst, *(int16_t*)src));
-    if (bt == jl_uint64_type)  return jl_box_uint64(jl_atomic_exchange((_Atomic(uint64_t)*)dst, *(uint64_t*)src));
-    if (bt == jl_uint32_type)  return jl_box_uint32(jl_atomic_exchange((_Atomic(uint32_t)*)dst, *(uint32_t*)src));
-    if (bt == jl_uint16_type)  return jl_box_uint16(jl_atomic_exchange((_Atomic(uint16_t)*)dst, *(uint16_t*)src));
-    if (bt == jl_char_type)    return jl_box_char(jl_atomic_exchange((_Atomic(uint32_t)*)dst, *(uint32_t*)src));
+    if (bt == jl_bool_type)    return (1 & jl_atomic_exchange((_JAtomic(int8_t)*)dst, 1 & *(int8_t*)src)) ? jl_true : jl_false;
+    if (bt == jl_uint8_type)   return jl_box_uint8(jl_atomic_exchange((_JAtomic(uint8_t)*)dst, *(int8_t*)src));
+    if (bt == jl_int64_type)   return jl_box_int64(jl_atomic_exchange((_JAtomic(int64_t)*)dst, *(int64_t*)src));
+    if (bt == jl_int32_type)   return jl_box_int32(jl_atomic_exchange((_JAtomic(int32_t)*)dst, *(int32_t*)src));
+    if (bt == jl_int8_type)    return jl_box_int8(jl_atomic_exchange((_JAtomic(int8_t)*)dst, *(int8_t*)src));
+    if (bt == jl_int16_type)   return jl_box_int16(jl_atomic_exchange((_JAtomic(int16_t)*)dst, *(int16_t*)src));
+    if (bt == jl_uint64_type)  return jl_box_uint64(jl_atomic_exchange((_JAtomic(uint64_t)*)dst, *(uint64_t*)src));
+    if (bt == jl_uint32_type)  return jl_box_uint32(jl_atomic_exchange((_JAtomic(uint32_t)*)dst, *(uint32_t*)src));
+    if (bt == jl_uint16_type)  return jl_box_uint16(jl_atomic_exchange((_JAtomic(uint16_t)*)dst, *(uint16_t*)src));
+    if (bt == jl_char_type)    return jl_box_char(jl_atomic_exchange((_JAtomic(uint32_t)*)dst, *(uint32_t*)src));
 
     jl_task_t *ct = jl_current_task;
     jl_value_t *v = jl_gc_alloc(ct->ptls, jl_datatype_size(bt), bt);
     if (nb == 1)
-        *(uint8_t*)v = jl_atomic_exchange((_Atomic(uint8_t)*)dst, *(uint8_t*)src);
+        *(uint8_t*)v = jl_atomic_exchange((_JAtomic(uint8_t)*)dst, *(uint8_t*)src);
     else if (nb == 2)
-        *(uint16_t*)v = jl_atomic_exchange((_Atomic(uint16_t)*)dst, *(uint16_t*)src);
+        *(uint16_t*)v = jl_atomic_exchange((_JAtomic(uint16_t)*)dst, *(uint16_t*)src);
     else if (nb <= 4)
-        *(uint32_t*)v = jl_atomic_exchange((_Atomic(uint32_t)*)dst, zext_read32(src, nb));
+        *(uint32_t*)v = jl_atomic_exchange((_JAtomic(uint32_t)*)dst, zext_read32(src, nb));
 #if MAX_POINTERATOMIC_SIZE >= 8
     else if (nb <= 8)
-        *(uint64_t*)v = jl_atomic_exchange((_Atomic(uint64_t)*)dst, zext_read64(src, nb));
+        *(uint64_t*)v = jl_atomic_exchange((_JAtomic(uint64_t)*)dst, zext_read64(src, nb));
 #endif
 #if MAX_POINTERATOMIC_SIZE >= 16
     else if (nb <= 16)
-        *(jl_uint128_t*)v = jl_atomic_exchange((_Atomic(jl_uint128_t)*)dst, zext_read128(src, nb));
+        *(jl_uint128_t*)v = jl_atomic_exchange((_JAtomic(jl_uint128_t)*)dst, zext_read128(src, nb));
 #endif
     else
         abort();
@@ -1047,29 +1047,29 @@ JL_DLLEXPORT int jl_atomic_bool_cmpswap_bits(char *dst, const jl_value_t *expect
     }
     else if (nb == 1) {
         uint8_t y = *(uint8_t*)expected;
-        success = jl_atomic_cmpswap((_Atomic(uint8_t)*)dst, &y, *(uint8_t*)src);
+        success = jl_atomic_cmpswap((_JAtomic(uint8_t)*)dst, &y, *(uint8_t*)src);
     }
     else if (nb == 2) {
         uint16_t y = *(uint16_t*)expected;
-        success = jl_atomic_cmpswap((_Atomic(uint16_t)*)dst, &y, *(uint16_t*)src);
+        success = jl_atomic_cmpswap((_JAtomic(uint16_t)*)dst, &y, *(uint16_t*)src);
     }
     else if (nb <= 4) {
         uint32_t y = zext_read32(expected, nb);
         uint32_t z = zext_read32(src, nb);
-        success = jl_atomic_cmpswap((_Atomic(uint32_t)*)dst, &y, z);
+        success = jl_atomic_cmpswap((_JAtomic(uint32_t)*)dst, &y, z);
     }
 #if MAX_POINTERATOMIC_SIZE >= 8
     else if (nb <= 8) {
         uint64_t y = zext_read64(expected, nb);
         uint64_t z = zext_read64(src, nb);
-        success = jl_atomic_cmpswap((_Atomic(uint64_t)*)dst, &y, z);
+        success = jl_atomic_cmpswap((_JAtomic(uint64_t)*)dst, &y, z);
     }
 #endif
 #if MAX_POINTERATOMIC_SIZE >= 16
     else if (nb <= 16) {
         jl_uint128_t y = zext_read128(expected, nb);
         jl_uint128_t z = zext_read128(src, nb);
-        success = jl_atomic_cmpswap((_Atomic(jl_uint128_t)*)dst, &y, z);
+        success = jl_atomic_cmpswap((_JAtomic(jl_uint128_t)*)dst, &y, z);
     }
 #endif
     else {
@@ -1096,10 +1096,10 @@ JL_DLLEXPORT jl_value_t *jl_atomic_cmpswap_bits(jl_datatype_t *dt, jl_datatype_t
         if (dt == et) {
             *y8 = *(uint8_t*)expected;
             uint8_t z8 = *(uint8_t*)src;
-            success = jl_atomic_cmpswap((_Atomic(uint8_t)*)dst, y8, z8);
+            success = jl_atomic_cmpswap((_JAtomic(uint8_t)*)dst, y8, z8);
         }
         else {
-            *y8 = jl_atomic_load((_Atomic(uint8_t)*)dst);
+            *y8 = jl_atomic_load((_JAtomic(uint8_t)*)dst);
             success = 0;
         }
     }
@@ -1109,10 +1109,10 @@ JL_DLLEXPORT jl_value_t *jl_atomic_cmpswap_bits(jl_datatype_t *dt, jl_datatype_t
         if (dt == et) {
             *y16 = *(uint16_t*)expected;
             uint16_t z16 = *(uint16_t*)src;
-            success = jl_atomic_cmpswap((_Atomic(uint16_t)*)dst, y16, z16);
+            success = jl_atomic_cmpswap((_JAtomic(uint16_t)*)dst, y16, z16);
         }
         else {
-            *y16 = jl_atomic_load((_Atomic(uint16_t)*)dst);
+            *y16 = jl_atomic_load((_JAtomic(uint16_t)*)dst);
             success = 0;
         }
     }
@@ -1122,13 +1122,13 @@ JL_DLLEXPORT jl_value_t *jl_atomic_cmpswap_bits(jl_datatype_t *dt, jl_datatype_t
             *y32 = zext_read32(expected, nb);
             uint32_t z32 = zext_read32(src, nb);
             while (1) {
-                success = jl_atomic_cmpswap((_Atomic(uint32_t)*)dst, y32, z32);
+                success = jl_atomic_cmpswap((_JAtomic(uint32_t)*)dst, y32, z32);
                 if (success || !dt->layout->haspadding || !jl_egal__bits(y, expected, dt))
                     break;
             }
         }
         else {
-            *y32 = jl_atomic_load((_Atomic(uint32_t)*)dst);
+            *y32 = jl_atomic_load((_JAtomic(uint32_t)*)dst);
             success = 0;
         }
     }
@@ -1139,13 +1139,13 @@ JL_DLLEXPORT jl_value_t *jl_atomic_cmpswap_bits(jl_datatype_t *dt, jl_datatype_t
             *y64 = zext_read64(expected, nb);
             uint64_t z64 = zext_read64(src, nb);
             while (1) {
-                success = jl_atomic_cmpswap((_Atomic(uint64_t)*)dst, y64, z64);
+                success = jl_atomic_cmpswap((_JAtomic(uint64_t)*)dst, y64, z64);
                 if (success || !dt->layout->haspadding || !jl_egal__bits(y, expected, dt))
                     break;
             }
         }
         else {
-            *y64 = jl_atomic_load((_Atomic(uint64_t)*)dst);
+            *y64 = jl_atomic_load((_JAtomic(uint64_t)*)dst);
             success = 0;
         }
     }
@@ -1157,13 +1157,13 @@ JL_DLLEXPORT jl_value_t *jl_atomic_cmpswap_bits(jl_datatype_t *dt, jl_datatype_t
             *y128 = zext_read128(expected, nb);
             jl_uint128_t z128 = zext_read128(src, nb);
             while (1) {
-                success = jl_atomic_cmpswap((_Atomic(jl_uint128_t)*)dst, y128, z128);
+                success = jl_atomic_cmpswap((_JAtomic(jl_uint128_t)*)dst, y128, z128);
                 if (success || !dt->layout->haspadding || !jl_egal__bits(y, expected, dt))
                     break;
             }
         }
         else {
-            *y128 = jl_atomic_load((_Atomic(jl_uint128_t)*)dst);
+            *y128 = jl_atomic_load((_JAtomic(jl_uint128_t)*)dst);
             success = 0;
         }
     }
@@ -1523,7 +1523,7 @@ JL_DLLEXPORT jl_value_t *jl_get_nth_field(jl_value_t *v, size_t i)
         jl_bounds_error_int(v, i + 1);
     size_t offs = jl_field_offset(st, i);
     if (jl_field_isptr(st, i)) {
-        return jl_atomic_load_relaxed((_Atomic(jl_value_t*)*)((char*)v + offs));
+        return jl_atomic_load_relaxed((_JAtomic(jl_value_t*)*)((char*)v + offs));
     }
     jl_value_t *ty = jl_field_type_concrete(st, i);
     int isatomic = jl_field_isatomic(st, i);
@@ -1560,7 +1560,7 @@ JL_DLLEXPORT jl_value_t *jl_get_nth_field_noalloc(jl_value_t *v JL_PROPAGATES_RO
     assert(i < jl_datatype_nfields(st));
     size_t offs = jl_field_offset(st,i);
     assert(jl_field_isptr(st,i));
-    return jl_atomic_load_relaxed((_Atomic(jl_value_t*)*)((char*)v + offs));
+    return jl_atomic_load_relaxed((_JAtomic(jl_value_t*)*)((char*)v + offs));
 }
 
 JL_DLLEXPORT jl_value_t *jl_get_nth_field_checked(jl_value_t *v, size_t i)
@@ -1602,7 +1602,7 @@ void set_nth_field(jl_datatype_t *st, jl_value_t *v, size_t i, jl_value_t *rhs,
         return;
     }
     if (jl_field_isptr(st, i)) {
-        jl_atomic_store_release((_Atomic(jl_value_t*)*)((char*)v + offs), rhs);
+        jl_atomic_store_release((_JAtomic(jl_value_t*)*)((char*)v + offs), rhs);
         jl_gc_wb(v, rhs);
     }
     else {
@@ -1652,9 +1652,9 @@ jl_value_t *swap_nth_field(jl_datatype_t *st, jl_value_t *v, size_t i, jl_value_
     jl_value_t *r;
     if (jl_field_isptr(st, i)) {
         if (isatomic)
-            r = jl_atomic_exchange((_Atomic(jl_value_t*)*)((char*)v + offs), rhs);
+            r = jl_atomic_exchange((_JAtomic(jl_value_t*)*)((char*)v + offs), rhs);
         else
-            r = jl_atomic_exchange_relaxed((_Atomic(jl_value_t*)*)((char*)v + offs), rhs);
+            r = jl_atomic_exchange_relaxed((_JAtomic(jl_value_t*)*)((char*)v + offs), rhs);
         jl_gc_wb(v, rhs);
     }
     else {
@@ -1724,7 +1724,7 @@ jl_value_t *modify_nth_field(jl_datatype_t *st, jl_value_t *v, size_t i, jl_valu
         if (!jl_isa(y, ty))
             jl_type_error("modifyfield!", ty, y);
         if (jl_field_isptr(st, i)) {
-            _Atomic(jl_value_t*) *p = (_Atomic(jl_value_t*)*)((char*)v + offs);
+            _JAtomic(jl_value_t*) *p = (_JAtomic(jl_value_t*)*)((char*)v + offs);
             if (isatomic ? jl_atomic_cmpswap(p, &r, y) : jl_atomic_cmpswap_relaxed(p, &r, y))
                 break;
         }
@@ -1803,7 +1803,7 @@ jl_value_t *replace_nth_field(jl_datatype_t *st, jl_value_t *v, size_t i, jl_val
     jl_datatype_t *rettyp = jl_apply_cmpswap_type(ty);
     JL_GC_PROMISE_ROOTED(rettyp); // (JL_ALWAYS_LEAFTYPE)
     if (jl_field_isptr(st, i)) {
-        _Atomic(jl_value_t*) *p = (_Atomic(jl_value_t*)*)((char*)v + offs);
+        _JAtomic(jl_value_t*) *p = (_JAtomic(jl_value_t*)*)((char*)v + offs);
         int success;
         while (1) {
             success = isatomic ? jl_atomic_cmpswap(p, &r, rhs) : jl_atomic_cmpswap_relaxed(p, &r, rhs);
@@ -1889,7 +1889,7 @@ JL_DLLEXPORT int jl_field_isdefined(jl_value_t *v, size_t i) JL_NOTSAFEPOINT
 {
     jl_datatype_t *st = (jl_datatype_t*)jl_typeof(v);
     size_t offs = jl_field_offset(st, i);
-    _Atomic(jl_value_t*) *fld = (_Atomic(jl_value_t*)*)((char*)v + offs);
+    _JAtomic(jl_value_t*) *fld = (_JAtomic(jl_value_t*)*)((char*)v + offs);
     if (!jl_field_isptr(st, i)) {
         jl_datatype_t *ft = (jl_datatype_t*)jl_field_type_concrete(st, i);
         if (!jl_is_datatype(ft) || ft->layout->first_ptr < 0)
diff --git a/src/flisp/Makefile b/src/flisp/Makefile
index 7bb929c61..0a71c5d95 100644
--- a/src/flisp/Makefile
+++ b/src/flisp/Makefile
@@ -26,30 +26,33 @@ NATIVE_BUILDDIR := $(BUILDDIR)
 LLT_BUILDDIR := $(BUILDDIR)/$(LLTDIR)
 endif
 
-HEADERS := $(wildcard *.h) $(LIBUV_INC)/uv.h $(wildcard $(LLTDIR)/*.h)
-
+HEADERS := $(wildcard *.h) $(wildcard $(LLTDIR)/*.h)
+#$(LIBUV_INC)/uv.h
 OBJS := $(SRCS:%.c=$(BUILDDIR)/%.o)
 DOBJS := $(SRCS:%.c=$(BUILDDIR)/%.dbg.obj)
 LLT_release := $(LLT_BUILDDIR)/libsupport.a
 LLT_debug := $(LLT_BUILDDIR)/libsupport-debug.a
-LIBFILES_release := $(LLT_release) $(LIBUV)
-LIBFILES_debug := $(LLT_debug) $(LIBUV)
-LIBS :=
+LIBFILES_release := $(LLT_release)
+#$(LIBUV)
+LIBFILES_debug := $(LLT_debug)
+#$(LIBUV)
+LIBS += -luv
 ifneq ($(OS),WINNT)
-LIBS += -lpthread
+#LIBS += -lpthread
 endif
 
 ifeq ($(USE_SYSTEM_UTF8PROC),0)
 LIBFILES_release += $(LIBUTF8PROC)
 LIBFILES_debug += $(LIBUTF8PROC)
 else
-LIBS += $(LIBUTF8PROC)
+LIBS += -lutf8proc
 endif
 
 
 FLAGS := -I$(LLTSRCDIR) $(JCFLAGS) $(HFILEDIRS:%=-I%) \
-        -I$(LIBUV_INC) -I$(UTF8PROC_INC) -I$(build_includedir) $(LIBDIRS:%=-L%) \
-        -DLIBRARY_EXPORTS -DUTF8PROC_EXPORTS
+        -I$(build_includedir) $(LIBDIRS:%=-L%) \
+        -DLIBRARY_EXPORTS
+#-I$(LIBUV_INC) -I$(UTF8PROC_INC) -DUTF8PROC_EXPORTS
 ifneq ($(OS), emscripten)
 FLAGS += -DUSE_COMPUTED_GOTO
 endif
diff --git a/src/flisp/flisp.c b/src/flisp/flisp.c
index 32c000802..fe53517c1 100644
--- a/src/flisp/flisp.c
+++ b/src/flisp/flisp.c
@@ -41,8 +41,9 @@
 #include <locale.h>
 #include <limits.h>
 #include <errno.h>
+#ifndef _MSC_VER
 #include <libgen.h> // defines dirname
-
+#endif
 #include "platform.h"
 #include "libsupport.h"
 #include "flisp.h"
@@ -915,7 +916,11 @@ static uint32_t process_keys(fl_context_t *fl_ctx, value_t kwtable,
     uintptr_t n;
     uint32_t extr = nopt+nkw;
     uint32_t ntot = nreq+extr;
+#ifndef _MSC_VER 
     value_t *args = (value_t*)alloca(extr*sizeof(value_t));
+#else
+    value_t *args = (value_t*)_alloca(extr*sizeof(value_t));
+#endif
     value_t v;
     uint32_t i, a = 0, nrestargs;
     value_t s1 = fl_ctx->Stack[fl_ctx->SP-1];
@@ -2406,7 +2411,20 @@ static void lisp_init(fl_context_t *fl_ctx, size_t initial_heapsize)
     char exename[1024];
     size_t exe_size = sizeof(exename) / sizeof(exename[0]);
     if ( uv_exepath(exename, &exe_size) == 0 ) {
+#ifdef _MSC_VER
+        char dir[1024];
+        strcpy(dir, exename);
+        char * last_path_sep = strrchr(dir,'\\');
+        if(last_path_sep != NULL) {
+          last_path_sep[0] = '\0';
+        } else {
+          dir[0] = '.';
+          dir[1] = '\0';
+        }
+        setc(symbol(fl_ctx, "*install-dir*"), cvalue_static_cstring(fl_ctx, strdup(dir)));
+#else
         setc(symbol(fl_ctx, "*install-dir*"), cvalue_static_cstring(fl_ctx, strdup(dirname(exename))));
+#endif
     }
 
     fl_ctx->memory_exception_value = fl_list2(fl_ctx, fl_ctx->OutOfMemoryError,
diff --git a/src/gc-stacks.c b/src/gc-stacks.c
index b35c1722c..790e22ac6 100644
--- a/src/gc-stacks.c
+++ b/src/gc-stacks.c
@@ -23,7 +23,7 @@
 #define MIN_STACK_MAPPINGS_PER_POOL 5
 
 const size_t jl_guard_size = (4096 * 8);
-static _Atomic(uint32_t) num_stack_mappings = 0;
+static _JAtomic(uint32_t) num_stack_mappings = 0;
 
 #ifdef _OS_WINDOWS_
 #define MAP_FAILED NULL
diff --git a/src/gc.c b/src/gc.c
index da79a5806..dab6d2d50 100644
--- a/src/gc.c
+++ b/src/gc.c
@@ -135,7 +135,7 @@ jl_mutex_t heapsnapshot_lock;
 
 // Flag that tells us whether we need to support conservative marking
 // of objects.
-static _Atomic(int) support_conservative_marking = 0;
+static _JAtomic(int) support_conservative_marking = 0;
 
 /**
  * Note about GC synchronization:
@@ -199,7 +199,7 @@ static uintptr_t gc_img_max;
 // `to_finalize` should not have tagged pointers.
 arraylist_t finalizer_list_marked;
 arraylist_t to_finalize;
-JL_DLLEXPORT _Atomic(int) jl_gc_have_pending_finalizers = 0;
+JL_DLLEXPORT _JAtomic(int) jl_gc_have_pending_finalizers = 0;
 
 static int ptr_cmp(const void *l, const void *r)
 {
@@ -437,7 +437,7 @@ static void finalize_object(arraylist_t *list, jl_value_t *o,
     // This way, the mutation should not conflict with the owning thread,
     // which only writes to locations later than `len`
     // and will not resize the buffer without acquiring the lock.
-    size_t len = need_sync ? jl_atomic_load_acquire((_Atomic(size_t)*)&list->len) : list->len;
+    size_t len = need_sync ? jl_atomic_load_acquire((_JAtomic(size_t)*)&list->len) : list->len;
     size_t oldlen = len;
     void **items = list->items;
     size_t j = 0;
@@ -470,7 +470,7 @@ static void finalize_object(arraylist_t *list, jl_value_t *o,
         // The `memset` (like any other content mutation) has to be done
         // **before** the `cmpxchg` which publishes the length.
         memset(&items[len], 0, (oldlen - len) * sizeof(void*));
-        jl_atomic_cmpswap((_Atomic(size_t)*)&list->len, &oldlen, len);
+        jl_atomic_cmpswap((_JAtomic(size_t)*)&list->len, &oldlen, len);
     }
     else {
         list->len = len;
@@ -660,7 +660,7 @@ void jl_gc_add_finalizer_(jl_ptls_t ptls, void *v, void *f) JL_NOTSAFEPOINT
     // (only one thread since it needs to acquire the finalizer lock).
     // Similar to `finalize_object`, all content mutation has to be done
     // between the acquire and the release of the length.
-    size_t oldlen = jl_atomic_load_acquire((_Atomic(size_t)*)&a->len);
+    size_t oldlen = jl_atomic_load_acquire((_JAtomic(size_t)*)&a->len);
     if (__unlikely(oldlen + 2 > a->max)) {
         JL_LOCK_NOGC(&finalizers_lock);
         // `a->len` might have been modified.
@@ -674,7 +674,7 @@ void jl_gc_add_finalizer_(jl_ptls_t ptls, void *v, void *f) JL_NOTSAFEPOINT
     void **items = a->items;
     items[oldlen] = v;
     items[oldlen + 1] = f;
-    jl_atomic_store_release((_Atomic(size_t)*)&a->len, oldlen + 2);
+    jl_atomic_store_release((_JAtomic(size_t)*)&a->len, oldlen + 2);
 }
 
 JL_DLLEXPORT void jl_gc_add_ptr_finalizer(jl_ptls_t ptls, jl_value_t *v, void *f) JL_NOTSAFEPOINT
@@ -934,7 +934,7 @@ STATIC_INLINE int gc_setmark_tag(jl_taggedvalue_t *o, uint8_t mark_mode,
         assert((tag & 0x3) == mark_mode);
     }
     *bits = mark_mode;
-    tag = jl_atomic_exchange_relaxed((_Atomic(uintptr_t)*)&o->header, tag);
+    tag = jl_atomic_exchange_relaxed((_JAtomic(uintptr_t)*)&o->header, tag);
     verify_val(jl_valueof(o));
     return !gc_marked(tag);
 }
@@ -977,8 +977,8 @@ STATIC_INLINE void gc_setmark_pool_(jl_ptls_t ptls, jl_taggedvalue_t *o,
     jl_assume(page);
     if (mark_mode == GC_OLD_MARKED) {
         ptls->gc_cache.perm_scanned_bytes += page->osize;
-        static_assert(sizeof(_Atomic(uint16_t)) == sizeof(page->nold), "");
-        jl_atomic_fetch_add_relaxed((_Atomic(uint16_t)*)&page->nold, 1);
+        static_assert(sizeof(_JAtomic(uint16_t)) == sizeof(page->nold), "");
+        jl_atomic_fetch_add_relaxed((_JAtomic(uint16_t)*)&page->nold, 1);
     }
     else {
         ptls->gc_cache.scanned_bytes += page->osize;
@@ -987,7 +987,7 @@ STATIC_INLINE void gc_setmark_pool_(jl_ptls_t ptls, jl_taggedvalue_t *o,
             char *page_begin = gc_page_data(o) + GC_PAGE_OFFSET;
             int obj_id = (((char*)o) - page_begin) / page->osize;
             uint8_t *ages = page->ages + obj_id / 8;
-            jl_atomic_fetch_and_relaxed((_Atomic(uint8_t)*)ages, ~(1 << (obj_id % 8)));
+            jl_atomic_fetch_and_relaxed((_JAtomic(uint8_t)*)ages, ~(1 << (obj_id % 8)));
         }
     }
     objprofile_count(jl_typeof(jl_valueof(o)),
@@ -3201,7 +3201,7 @@ static void sweep_finalizer_list(arraylist_t *list)
 }
 
 // collector entry point and control
-static _Atomic(uint32_t) jl_gc_disable_counter = 1;
+static _JAtomic(uint32_t) jl_gc_disable_counter = 1;
 
 JL_DLLEXPORT int jl_gc_enable(int on)
 {
@@ -3657,8 +3657,8 @@ JL_DLLEXPORT void jl_gc_collect(jl_gc_collection_t collection)
     if (jl_atomic_load_relaxed(&jl_gc_disable_counter)) {
         size_t localbytes = jl_atomic_load_relaxed(&ptls->gc_num.allocd) + gc_num.interval;
         jl_atomic_store_relaxed(&ptls->gc_num.allocd, -(int64_t)gc_num.interval);
-        static_assert(sizeof(_Atomic(uint64_t)) == sizeof(gc_num.deferred_alloc), "");
-        jl_atomic_fetch_add((_Atomic(uint64_t)*)&gc_num.deferred_alloc, localbytes);
+        static_assert(sizeof(_JAtomic(uint64_t)) == sizeof(gc_num.deferred_alloc), "");
+        jl_atomic_fetch_add((_JAtomic(uint64_t)*)&gc_num.deferred_alloc, localbytes);
         return;
     }
     jl_gc_debug_print();
diff --git a/src/gf.c b/src/gf.c
index cdbf2c724..473da795c 100644
--- a/src/gf.c
+++ b/src/gf.c
@@ -24,7 +24,7 @@
 extern "C" {
 #endif
 
-JL_DLLEXPORT _Atomic(size_t) jl_world_counter = 1; // uses atomic acquire/release
+JL_DLLEXPORT _JAtomic(size_t) jl_world_counter = 1; // uses atomic acquire/release
 JL_DLLEXPORT size_t jl_get_world_counter(void) JL_NOTSAFEPOINT
 {
     return jl_atomic_load_acquire(&jl_world_counter);
@@ -120,7 +120,7 @@ static jl_method_instance_t *jl_specializations_get_linfo_(jl_method_t *m JL_PRO
             }
         }
         else {
-            _Atomic(jl_method_instance_t*) *data = (_Atomic(jl_method_instance_t*)*)jl_svec_data(specializations);
+            _JAtomic(jl_method_instance_t*) *data = (_JAtomic(jl_method_instance_t*)*)jl_svec_data(specializations);
             JL_GC_PUSH1(&specializations); // clang-sa doesn't realize this loop uses specializations
             for (i = cl; i > 0; i--) {
                 jl_method_instance_t *mi = jl_atomic_load_relaxed(&data[i - 1]);
@@ -142,7 +142,7 @@ static jl_method_instance_t *jl_specializations_get_linfo_(jl_method_t *m JL_PRO
         }
         else {
             if (hv) {
-                _Atomic(jl_method_instance_t*) *data = (_Atomic(jl_method_instance_t*)*)jl_svec_data(specializations);
+                _JAtomic(jl_method_instance_t*) *data = (_JAtomic(jl_method_instance_t*)*)jl_svec_data(specializations);
                 for (i = 0; i < cl; i++) {
                     jl_method_instance_t *mi = jl_atomic_load_relaxed(&data[i]);
                     if ((jl_value_t*)mi == jl_nothing)
@@ -1136,7 +1136,7 @@ static inline jl_typemap_entry_t *lookup_leafcache(jl_array_t *leafcache JL_PROP
 }
 
 static jl_method_instance_t *cache_method(
-        jl_methtable_t *mt, _Atomic(jl_typemap_t*) *cache, jl_value_t *parent JL_PROPAGATES_ROOT,
+        jl_methtable_t *mt, _JAtomic(jl_typemap_t*) *cache, jl_value_t *parent JL_PROPAGATES_ROOT,
         jl_tupletype_t *tt, // the original tupletype of the signature
         jl_method_t *definition,
         size_t world, size_t min_valid, size_t max_valid,
@@ -1966,7 +1966,7 @@ JL_DLLEXPORT void jl_method_table_insert(jl_methtable_t *mt, jl_method_t *method
                 if (morespec[j] == (char)morespec_is)
                     continue;
                 jl_svec_t *specializations = jl_atomic_load_relaxed(&m->specializations);
-                _Atomic(jl_method_instance_t*) *data = (_Atomic(jl_method_instance_t*)*)jl_svec_data(specializations);
+                _JAtomic(jl_method_instance_t*) *data = (_JAtomic(jl_method_instance_t*)*)jl_svec_data(specializations);
                 size_t i, l = jl_svec_len(specializations);
                 enum morespec_options ambig = morespec_unknown;
                 for (i = 0; i < l; i++) {
@@ -2785,8 +2785,8 @@ STATIC_INLINE int sig_match_fast(jl_value_t *arg1t, jl_value_t **args, jl_value_
     return 1;
 }
 
-_Atomic(jl_typemap_entry_t*) call_cache[N_CALL_CACHE] JL_GLOBALLY_ROOTED;
-static _Atomic(uint8_t) pick_which[N_CALL_CACHE];
+_JAtomic(jl_typemap_entry_t*) call_cache[N_CALL_CACHE] JL_GLOBALLY_ROOTED;
+static _JAtomic(uint8_t) pick_which[N_CALL_CACHE];
 #ifdef JL_GF_PROFILE
 size_t ncalls;
 void call_cache_stats()
diff --git a/src/iddict.c b/src/iddict.c
index 1fa8a67d1..0353ee87e 100644
--- a/src/iddict.c
+++ b/src/iddict.c
@@ -43,7 +43,7 @@ static inline int jl_table_assign_bp(jl_array_t **pa, jl_value_t *key, jl_value_
         *pa = a;
     }
     size_t maxprobe = max_probe(sz);
-    _Atomic(jl_value_t*) *tab = (_Atomic(jl_value_t*)*)a->data;
+    _JAtomic(jl_value_t*) *tab = (_JAtomic(jl_value_t*)*)a->data;
 
     hv = keyhash(key);
     while (1) {
@@ -102,20 +102,20 @@ static inline int jl_table_assign_bp(jl_array_t **pa, jl_value_t *key, jl_value_
         *pa = jl_idtable_rehash(*pa, newsz);
 
         a = *pa;
-        tab = (_Atomic(jl_value_t*)*)a->data;
+        tab = (_JAtomic(jl_value_t*)*)a->data;
         sz = hash_size(a);
         maxprobe = max_probe(sz);
     }
 }
 
 /* returns bp if key is in hash, otherwise NULL */
-inline _Atomic(jl_value_t*) *jl_table_peek_bp(jl_array_t *a, jl_value_t *key) JL_NOTSAFEPOINT
+inline _JAtomic(jl_value_t*) *jl_table_peek_bp(jl_array_t *a, jl_value_t *key) JL_NOTSAFEPOINT
 {
     size_t sz = hash_size(a);
     if (sz == 0)
         return NULL;
     size_t maxprobe = max_probe(sz);
-    _Atomic(jl_value_t*) *tab = (_Atomic(jl_value_t*)*)a->data;
+    _JAtomic(jl_value_t*) *tab = (_JAtomic(jl_value_t*)*)a->data;
     uint_t hv = keyhash(key);
     size_t index = h2index(hv, sz);
     sz *= 2;
@@ -155,20 +155,20 @@ jl_array_t *jl_eqtable_put(jl_array_t *h, jl_value_t *key, jl_value_t *val, int
 JL_DLLEXPORT
 jl_value_t *jl_eqtable_get(jl_array_t *h, jl_value_t *key, jl_value_t *deflt) JL_NOTSAFEPOINT
 {
-    _Atomic(jl_value_t*) *bp = jl_table_peek_bp(h, key);
+    _JAtomic(jl_value_t*) *bp = jl_table_peek_bp(h, key);
     return (bp == NULL) ? deflt : jl_atomic_load_relaxed(bp);
 }
 
 jl_value_t *jl_eqtable_getkey(jl_array_t *h, jl_value_t *key, jl_value_t *deflt) JL_NOTSAFEPOINT
 {
-    _Atomic(jl_value_t*) *bp = jl_table_peek_bp(h, key);
+    _JAtomic(jl_value_t*) *bp = jl_table_peek_bp(h, key);
     return (bp == NULL) ? deflt : jl_atomic_load_relaxed(bp - 1);
 }
 
 JL_DLLEXPORT
 jl_value_t *jl_eqtable_pop(jl_array_t *h, jl_value_t *key, jl_value_t *deflt, int *found)
 {
-    _Atomic(jl_value_t*) *bp = jl_table_peek_bp(h, key);
+    _JAtomic(jl_value_t*) *bp = jl_table_peek_bp(h, key);
     if (found)
         *found = (bp != NULL);
     if (bp == NULL)
diff --git a/src/init.c b/src/init.c
index 89f4153ff..0ad6a12af 100644
--- a/src/init.c
+++ b/src/init.c
@@ -11,8 +11,13 @@
 #include <stdio.h>
 #include <fcntl.h>
 #include <errno.h>
+#ifndef _MSC_VER
 #include <libgen.h> // defines dirname
-
+#else
+#define UV_STDIN_FD (HANDLE)STD_INPUT_HANDLE 
+#define UV_STDOUT_FD (HANDLE)STD_OUTPUT_HANDLE 
+#define UV_STDERR_FD (HANDLE)STD_ERROR_HANDLE 
+#endif
 #if !defined(_OS_WINDOWS_) || defined(_COMPILER_GCC_)
 #include <getopt.h>
 #endif
@@ -442,10 +447,10 @@ static void *init_stdio_handle(const char *stdio, uv_os_fd_t fd, int readable)
     // This also helps limit the impact other libraries can cause on our file handle.
     if ((err = uv_dup(fd, &fd)))
         jl_errorf("error initializing %s in uv_dup: %s (%s %d)", stdio, uv_strerror(err), uv_err_name(err), err);
-    switch(uv_guess_handle(fd)) {
+    switch(uv_guess_handle((int)fd)) {
     case UV_TTY:
         handle = malloc_s(sizeof(uv_tty_t));
-        if ((err = uv_tty_init(jl_io_loop, (uv_tty_t*)handle, fd, 0))) {
+        if ((err = uv_tty_init(jl_io_loop, (uv_tty_t*)handle, (int)fd, 0))) {
             jl_errorf("error initializing %s in uv_tty_init: %s (%s %d)", stdio, uv_strerror(err), uv_err_name(err), err);
         }
         ((uv_tty_t*)handle)->data = NULL;
@@ -488,7 +493,7 @@ static void *init_stdio_handle(const char *stdio, uv_os_fd_t fd, int readable)
         if ((err = uv_pipe_init(jl_io_loop, (uv_pipe_t*)handle, 0))) {
             jl_errorf("error initializing %s in uv_pipe_init: %s (%s %d)", stdio, uv_strerror(err), uv_err_name(err), err);
         }
-        if ((err = uv_pipe_open((uv_pipe_t*)handle, fd))) {
+        if ((err = uv_pipe_open((uv_pipe_t*)handle, (int)fd))) {
             jl_errorf("error initializing %s in uv_pipe_open: %s (%s %d)", stdio, uv_strerror(err), uv_err_name(err), err);
         }
         ((uv_pipe_t*)handle)->data = NULL;
@@ -634,7 +639,20 @@ static void jl_resolve_sysimg_location(JL_IMAGE_SEARCH rel)
     if (!jl_options.julia_bindir) {
         jl_options.julia_bindir = getenv("JULIA_BINDIR");
         if (!jl_options.julia_bindir) {
-            jl_options.julia_bindir = dirname(free_path);
+#ifdef _MSC_VER
+        char dir[JL_PATH_MAX];
+        strcpy(dir, free_path);
+        char * last_path_sep = strrchr(dir,'\\');
+        if(last_path_sep != NULL) {
+          last_path_sep[0] = '\0';
+        } else {
+          dir[0] = '.';
+          dir[1] = '\0';
+        }
+        strcpy(jl_options.julia_bindir, dir);
+#else
+        jl_options.julia_bindir = dirname(free_path);
+#endif
         }
     }
     if (jl_options.julia_bindir)
diff --git a/src/interpreter.c b/src/interpreter.c
index 1f9c416d9..298408c33 100644
--- a/src/interpreter.c
+++ b/src/interpreter.c
@@ -93,7 +93,7 @@ static jl_value_t *eval_methoddef(jl_expr_t *ex, interpreter_state *s)
         }
         jl_value_t *bp_owner = (jl_value_t*)modu;
         jl_binding_t *b = jl_get_binding_for_method_def(modu, fname);
-        _Atomic(jl_value_t*) *bp = &b->value;
+        _JAtomic(jl_value_t*) *bp = &b->value;
         jl_value_t *gf = jl_generic_function_def(b->name, b->owner, bp, bp_owner, b);
         return gf;
     }
@@ -659,7 +659,7 @@ jl_code_info_t *jl_code_for_interpreter(jl_method_instance_t *mi)
 
 // interpreter entry points
 
-jl_value_t *NOINLINE jl_fptr_interpret_call(jl_value_t *f, jl_value_t **args, uint32_t nargs, jl_code_instance_t *codeinst)
+NOINLINE jl_value_t * jl_fptr_interpret_call(jl_value_t *f, jl_value_t **args, uint32_t nargs, jl_code_instance_t *codeinst)
 {
     interpreter_state *s;
     jl_method_instance_t *mi = codeinst->def;
@@ -744,7 +744,7 @@ jl_value_t *jl_interpret_opaque_closure(jl_opaque_closure_t *oc, jl_value_t **ar
     return r;
 }
 
-jl_value_t *NOINLINE jl_interpret_toplevel_thunk(jl_module_t *m, jl_code_info_t *src)
+NOINLINE jl_value_t * jl_interpret_toplevel_thunk(jl_module_t *m, jl_code_info_t *src)
 {
     interpreter_state *s;
     unsigned nroots = jl_source_nslots(src) + jl_source_nssavalues(src);
@@ -768,7 +768,7 @@ jl_value_t *NOINLINE jl_interpret_toplevel_thunk(jl_module_t *m, jl_code_info_t
 // deprecated: do not use this method in new code
 // it uses special scoping / evaluation / error rules
 // which should instead be handled in lowering
-jl_value_t *NOINLINE jl_interpret_toplevel_expr_in(jl_module_t *m, jl_value_t *e, jl_code_info_t *src, jl_svec_t *sparam_vals)
+NOINLINE jl_value_t * jl_interpret_toplevel_expr_in(jl_module_t *m, jl_value_t *e, jl_code_info_t *src, jl_svec_t *sparam_vals)
 {
     interpreter_state *s;
     jl_value_t **locals;
diff --git a/src/jl_exported_data.inc b/src/jl_exported_data.inc
index 6f0671ef0..ecb3149ac 100644
--- a/src/jl_exported_data.inc
+++ b/src/jl_exported_data.inc
@@ -131,7 +131,7 @@
 // Data symbols that are defined inside the public libjulia
 #define JL_EXPORTED_DATA_SYMBOLS(XX) \
     XX(jl_n_threadpools, int) \
-    XX(jl_n_threads, _Atomic(int)) \
+    XX(jl_n_threads, _JAtomic(int)) \
     XX(jl_options, jl_options_t) \
 
 // end of file
diff --git a/src/jl_uv.c b/src/jl_uv.c
index 97a6602c1..45dbe1585 100644
--- a/src/jl_uv.c
+++ b/src/jl_uv.c
@@ -52,7 +52,7 @@ void jl_init_uv(void)
     JL_MUTEX_INIT(&jl_uv_mutex); // a file-scope initializer can be used instead
 }
 
-_Atomic(int) jl_uv_n_waiters = 0;
+_JAtomic(int) jl_uv_n_waiters = 0;
 
 void JL_UV_LOCK(void)
 {
@@ -202,7 +202,7 @@ JL_DLLEXPORT void jl_uv_req_set_data(uv_req_t *req, void *data) { req->data = da
 JL_DLLEXPORT void *jl_uv_handle_data(uv_handle_t *handle) { return handle->data; }
 JL_DLLEXPORT void *jl_uv_write_handle(uv_write_t *req) { return req->handle; }
 
-extern _Atomic(unsigned) _threadedregion;
+extern _JAtomic(unsigned) _threadedregion;
 
 JL_DLLEXPORT int jl_process_events(void)
 {
diff --git a/src/jltypes.c b/src/jltypes.c
index bf1fd6d45..167a06381 100644
--- a/src/jltypes.c
+++ b/src/jltypes.c
@@ -19,7 +19,7 @@
 extern "C" {
 #endif
 
-_Atomic(jl_value_t*) cmpswap_names JL_GLOBALLY_ROOTED;
+_JAtomic(jl_value_t*) cmpswap_names JL_GLOBALLY_ROOTED;
 
 // compute empirical max-probe for a given size
 #define max_probe(size) ((size) <= 1024 ? 16 : (size) >> 6)
@@ -788,7 +788,7 @@ static jl_datatype_t *lookup_type_set(jl_svec_t *cache, jl_value_t **key, size_t
     if (sz == 0)
         return NULL;
     size_t maxprobe = max_probe(sz);
-    _Atomic(jl_datatype_t*) *tab = (_Atomic(jl_datatype_t*)*)jl_svec_data(cache);
+    _JAtomic(jl_datatype_t*) *tab = (_JAtomic(jl_datatype_t*)*)jl_svec_data(cache);
     size_t index = h2index(hv, sz);
     size_t orig = index;
     size_t iter = 0;
@@ -811,7 +811,7 @@ static jl_datatype_t *lookup_type_setvalue(jl_svec_t *cache, jl_value_t *key1, j
     if (sz == 0)
         return NULL;
     size_t maxprobe = max_probe(sz);
-    _Atomic(jl_datatype_t*) *tab = (_Atomic(jl_datatype_t*)*)jl_svec_data(cache);
+    _JAtomic(jl_datatype_t*) *tab = (_JAtomic(jl_datatype_t*)*)jl_svec_data(cache);
     size_t index = h2index(hv, sz);
     size_t orig = index;
     size_t iter = 0;
@@ -834,7 +834,7 @@ static ssize_t lookup_type_idx_linear(jl_svec_t *cache, jl_value_t **key, size_t
 {
     if (n == 0)
         return -1;
-    _Atomic(jl_datatype_t*) *data = (_Atomic(jl_datatype_t*)*)jl_svec_data(cache);
+    _JAtomic(jl_datatype_t*) *data = (_JAtomic(jl_datatype_t*)*)jl_svec_data(cache);
     size_t cl = jl_svec_len(cache);
     ssize_t i;
     for (i = 0; i < cl; i++) {
@@ -851,7 +851,7 @@ static ssize_t lookup_type_idx_linearvalue(jl_svec_t *cache, jl_value_t *key1, j
 {
     if (n == 0)
         return -1;
-    _Atomic(jl_datatype_t*) *data = (_Atomic(jl_datatype_t*)*)jl_svec_data(cache);
+    _JAtomic(jl_datatype_t*) *data = (_JAtomic(jl_datatype_t*)*)jl_svec_data(cache);
     size_t cl = jl_svec_len(cache);
     ssize_t i;
     for (i = 0; i < cl; i++) {
@@ -903,7 +903,7 @@ static jl_value_t *lookup_typevalue(jl_typename_t *tn, jl_value_t *key1, jl_valu
 
 static int cache_insert_type_set_(jl_svec_t *a, jl_datatype_t *val, uint_t hv, int atomic)
 {
-    _Atomic(jl_value_t*) *tab = (_Atomic(jl_value_t*)*)jl_svec_data(a);
+    _JAtomic(jl_value_t*) *tab = (_JAtomic(jl_value_t*)*)jl_svec_data(a);
     size_t sz = jl_svec_len(a);
     if (sz <= 1)
         return 0;
diff --git a/src/julia.h b/src/julia.h
index e39a8d66c..f5d7c6e29 100644
--- a/src/julia.h
+++ b/src/julia.h
@@ -123,7 +123,7 @@ static inline void jl_set_typeof(void *v, void *t) JL_NOTSAFEPOINT
 {
     // Do not call this on a value that is already initialized.
     jl_taggedvalue_t *tag = jl_astaggedvalue(v);
-    jl_atomic_store_relaxed((_Atomic(jl_value_t*)*)&tag->type, (jl_value_t*)t);
+    jl_atomic_store_relaxed((_JAtomic(jl_value_t*)*)&tag->type, (jl_value_t*)t);
 }
 #define jl_typeis(v,t) (jl_typeof(v)==(jl_value_t*)(t))
 
@@ -131,8 +131,8 @@ static inline void jl_set_typeof(void *v, void *t) JL_NOTSAFEPOINT
 // The string data is nul-terminated and hangs off the end of the struct.
 typedef struct _jl_sym_t {
     JL_DATA_TYPE
-    _Atomic(struct _jl_sym_t*) left;
-    _Atomic(struct _jl_sym_t*) right;
+    _JAtomic(struct _jl_sym_t*) left;
+    _JAtomic(struct _jl_sym_t*) right;
     uintptr_t hash;    // precomputed hash value
     // JL_ATTRIBUTE_ALIGN_PTRSIZE(char name[]);
 } jl_sym_t;
@@ -307,13 +307,13 @@ typedef struct _jl_method_t {
     jl_value_t *sig;
 
     // table of all jl_method_instance_t specializations we have
-    _Atomic(jl_svec_t*) specializations; // allocated as [hashable, ..., NULL, linear, ....]
-    _Atomic(jl_array_t*) speckeyset; // index lookup by hash into specializations
+    _JAtomic(jl_svec_t*) specializations; // allocated as [hashable, ..., NULL, linear, ....]
+    _JAtomic(jl_array_t*) speckeyset; // index lookup by hash into specializations
 
     jl_value_t *slot_syms; // compacted list of slot names (String)
     jl_value_t *external_mt; // reference to the method table this method is part of, null if part of the internal table
     jl_value_t *source;  // original code template (jl_code_info_t, but may be compressed), null for builtins
-    _Atomic(struct _jl_method_instance_t*) unspecialized;  // unspecialized executable method instance, or null
+    _JAtomic(struct _jl_method_instance_t*) unspecialized;  // unspecialized executable method instance, or null
     jl_value_t *generator;  // executable code-generating function if available
     jl_array_t *roots;  // pointers in generated code (shared to reduce memory), or null
     // Identify roots by module-of-origin. We only track the module for roots added during incremental compilation.
@@ -325,7 +325,7 @@ typedef struct _jl_method_t {
     // cache of specializations of this method for invoke(), i.e.
     // cases where this method was called even though it was not necessarily
     // the most specific for the argument types.
-    _Atomic(jl_typemap_t*) invokes;
+    _JAtomic(jl_typemap_t*) invokes;
 
     // A function that compares two specializations of this method, returning
     // `true` if the first signature is to be considered "smaller" than the
@@ -368,7 +368,7 @@ struct _jl_method_instance_t {
     jl_value_t *uninferred; // cached uncompressed code, for generated functions, top-level thunks, or the interpreter
     jl_array_t *backedges; // list of method-instances which call this method-instance; `invoke` records (invokesig, caller) pairs
     jl_array_t *callbacks; // list of callback functions to inform external caches about invalidations
-    _Atomic(struct _jl_code_instance_t*) cache;
+    _JAtomic(struct _jl_code_instance_t*) cache;
     uint8_t inInference; // flags to tell if inference is running on this object
     uint8_t cache_with_orig; // !cache_with_specTypes
     uint8_t precompiled; // true if this instance was generated by an explicit `precompile(...)` call
@@ -388,7 +388,7 @@ typedef struct jl_opaque_closure_t {
 typedef struct _jl_code_instance_t {
     JL_DATA_TYPE
     jl_method_instance_t *def; // method this is specialized from
-    _Atomic(struct _jl_code_instance_t*) next; // pointer to the next cache entry
+    _JAtomic(struct _jl_code_instance_t*) next; // pointer to the next cache entry
 
     // world range for which this object is valid to use
     size_t min_world;
@@ -397,7 +397,7 @@ typedef struct _jl_code_instance_t {
     // inference state cache
     jl_value_t *rettype; // return type for fptr
     jl_value_t *rettype_const; // inferred constant return value, or null
-    _Atomic(jl_value_t *) inferred; // inferred jl_code_info_t, or jl_nothing, or null
+    _JAtomic(jl_value_t *) inferred; // inferred jl_code_info_t, or jl_nothing, or null
     //TODO: jl_array_t *edges; // stored information about edges from this object
     //TODO: uint8_t absolute_max; // whether true max world is unknown
 
@@ -430,22 +430,22 @@ typedef struct _jl_code_instance_t {
     };
 #else
     uint32_t ipo_purity_bits;
-    _Atomic(uint32_t) purity_bits;
+    _JAtomic(uint32_t) purity_bits;
 #endif
     jl_value_t *argescapes; // escape information of call arguments
 
     // compilation state cache
-    _Atomic(uint8_t) specsigflags; // & 0b001 == specptr is a specialized function signature for specTypes->rettype
+    _JAtomic(uint8_t) specsigflags; // & 0b001 == specptr is a specialized function signature for specTypes->rettype
                                    // & 0b010 == invokeptr matches specptr
                                    // & 0b100 == From image
-    _Atomic(uint8_t) precompile;  // if set, this will be added to the output system image
+    _JAtomic(uint8_t) precompile;  // if set, this will be added to the output system image
     uint8_t relocatability;  // nonzero if all roots are built into sysimg or tagged by module key
-    _Atomic(jl_callptr_t) invoke; // jlcall entry point
+    _JAtomic(jl_callptr_t) invoke; // jlcall entry point
     union _jl_generic_specptr_t {
-        _Atomic(void*) fptr;
-        _Atomic(jl_fptr_args_t) fptr1;
+        _JAtomic(void*) fptr;
+        _JAtomic(jl_fptr_args_t) fptr1;
         // 2 constant
-        _Atomic(jl_fptr_sparam_t) fptr3;
+        _JAtomic(jl_fptr_sparam_t) fptr3;
         // 4 interpreter
     } specptr; // private data for `jlcall entry point
 } jl_code_instance_t;
@@ -481,9 +481,9 @@ typedef struct {
     // `wrapper` is either the only instantiation of the type (if no parameters)
     // or a UnionAll accepting parameters to make an instantiation.
     jl_value_t *wrapper;
-    _Atomic(jl_value_t*) Typeofwrapper;  // cache for Type{wrapper}
-    _Atomic(jl_svec_t*) cache;        // sorted array
-    _Atomic(jl_svec_t*) linearcache;  // unsorted array
+    _JAtomic(jl_value_t*) Typeofwrapper;  // cache for Type{wrapper}
+    _JAtomic(jl_svec_t*) cache;        // sorted array
+    _JAtomic(jl_svec_t*) linearcache;  // unsorted array
     struct _jl_methtable_t *mt;
     jl_array_t *partial;     // incomplete instantiations of this type
     intptr_t hash;
@@ -575,10 +575,10 @@ typedef struct {
 typedef struct {
     // not first-class
     jl_sym_t *name;
-    _Atomic(jl_value_t*) value;
-    _Atomic(jl_value_t*) globalref;  // cached GlobalRef for this binding
+    _JAtomic(jl_value_t*) value;
+    _JAtomic(jl_value_t*) globalref;  // cached GlobalRef for this binding
     struct _jl_module_t* owner;  // for individual imported bindings -- TODO: make _Atomic
-    _Atomic(jl_value_t*) ty;  // binding type
+    _JAtomic(jl_value_t*) ty;  // binding type
     uint8_t constp:1;
     uint8_t exportp:1;
     uint8_t imported:1;
@@ -600,7 +600,7 @@ typedef struct _jl_module_t {
     jl_uuid_t build_id;
     jl_uuid_t uuid;
     size_t primary_world;
-    _Atomic(uint32_t) counter;
+    _JAtomic(uint32_t) counter;
     int32_t nospecialize;  // global bit flags: initialization for new methods
     int8_t optlevel;
     int8_t compile;
@@ -620,7 +620,7 @@ typedef struct {
 // one Type-to-Value entry
 typedef struct _jl_typemap_entry_t {
     JL_DATA_TYPE
-    _Atomic(struct _jl_typemap_entry_t*) next; // invasive linked list
+    _JAtomic(struct _jl_typemap_entry_t*) next; // invasive linked list
     jl_tupletype_t *sig; // the type signature for this entry
     jl_tupletype_t *simplesig; // a simple signature for fast rejection
     jl_svec_t *guardsigs;
@@ -645,23 +645,23 @@ typedef struct _jl_typemap_level_t {
     // next split may be on Type{T} as LeafTypes then TypeName's parents up to Any
     // next split may be on LeafType
     // next split may be on TypeName
-    _Atomic(jl_array_t*) arg1; // contains LeafType
-    _Atomic(jl_array_t*) targ; // contains Type{LeafType}
-    _Atomic(jl_array_t*) name1; // contains non-abstract TypeName, for parents up to (excluding) Any
-    _Atomic(jl_array_t*) tname; // contains a dict of Type{TypeName}, for parents up to Any
+    _JAtomic(jl_array_t*) arg1; // contains LeafType
+    _JAtomic(jl_array_t*) targ; // contains Type{LeafType}
+    _JAtomic(jl_array_t*) name1; // contains non-abstract TypeName, for parents up to (excluding) Any
+    _JAtomic(jl_array_t*) tname; // contains a dict of Type{TypeName}, for parents up to Any
     // next a linear list of things too complicated at this level for analysis (no more levels)
-    _Atomic(jl_typemap_entry_t*) linear;
+    _JAtomic(jl_typemap_entry_t*) linear;
     // finally, start a new level if the type at offs is Any
-    _Atomic(jl_typemap_t*) any;
+    _JAtomic(jl_typemap_t*) any;
 } jl_typemap_level_t;
 
 // contains the TypeMap for one Type
 typedef struct _jl_methtable_t {
     JL_DATA_TYPE
     jl_sym_t *name; // sometimes a hack used by serialization to handle kwsorter
-    _Atomic(jl_typemap_t*) defs;
-    _Atomic(jl_array_t*) leafcache;
-    _Atomic(jl_typemap_t*) cache;
+    _JAtomic(jl_typemap_t*) defs;
+    _JAtomic(jl_array_t*) leafcache;
+    _JAtomic(jl_typemap_t*) cache;
     intptr_t max_args;  // max # of non-vararg arguments in a signature
     jl_module_t *module; // used for incremental serialization to locate original binding
     jl_array_t *backedges; // (sig, caller::MethodInstance) pairs
@@ -986,7 +986,7 @@ STATIC_INLINE jl_value_t *jl_svecref(void *t JL_PROPAGATES_ROOT, size_t i) JL_NO
     assert(i < jl_svec_len(t));
     // while svec is supposedly immutable, in practice we sometimes publish it first
     // and set the values lazily
-    return jl_atomic_load_relaxed((_Atomic(jl_value_t*)*)jl_svec_data(t) + i);
+    return jl_atomic_load_relaxed((_JAtomic(jl_value_t*)*)jl_svec_data(t) + i);
 }
 STATIC_INLINE jl_value_t *jl_svecset(
     void *t JL_ROOTING_ARGUMENT JL_PROPAGATES_ROOT,
@@ -1025,7 +1025,7 @@ STATIC_INLINE jl_value_t *jl_array_ptr_ref(void *a JL_PROPAGATES_ROOT, size_t i)
 {
     assert(((jl_array_t*)a)->flags.ptrarray);
     assert(i < jl_array_len(a));
-    return jl_atomic_load_relaxed(((_Atomic(jl_value_t*)*)(jl_array_data(a))) + i);
+    return jl_atomic_load_relaxed(((_JAtomic(jl_value_t*)*)(jl_array_data(a))) + i);
 }
 STATIC_INLINE jl_value_t *jl_array_ptr_set(
     void *a JL_ROOTING_ARGUMENT, size_t i,
@@ -1033,7 +1033,7 @@ STATIC_INLINE jl_value_t *jl_array_ptr_set(
 {
     assert(((jl_array_t*)a)->flags.ptrarray);
     assert(i < jl_array_len(a));
-    jl_atomic_store_release(((_Atomic(jl_value_t*)*)(jl_array_data(a))) + i, (jl_value_t*)x);
+    jl_atomic_store_release(((_JAtomic(jl_value_t*)*)(jl_array_data(a))) + i, (jl_value_t*)x);
     if (x) {
         if (((jl_array_t*)a)->flags.how == 3) {
             a = jl_array_data_owner(a);
@@ -1499,7 +1499,7 @@ JL_DLLEXPORT jl_sym_t *jl_tagged_gensym(const char *str, size_t len);
 JL_DLLEXPORT jl_sym_t *jl_get_root_symbol(void);
 JL_DLLEXPORT jl_value_t *jl_generic_function_def(jl_sym_t *name,
                                                  jl_module_t *module,
-                                                 _Atomic(jl_value_t*) *bp, jl_value_t *bp_owner,
+                                                 _JAtomic(jl_value_t*) *bp, jl_value_t *bp_owner,
                                                  jl_binding_t *bnd);
 JL_DLLEXPORT jl_method_t *jl_method_def(jl_svec_t *argdata, jl_methtable_t *mt, jl_code_info_t *f, jl_module_t *module);
 JL_DLLEXPORT jl_code_info_t *jl_code_for_staged(jl_method_instance_t *linfo);
@@ -1683,7 +1683,7 @@ JL_DLLEXPORT jl_sym_t *jl_get_UNAME(void) JL_NOTSAFEPOINT;
 JL_DLLEXPORT jl_sym_t *jl_get_ARCH(void) JL_NOTSAFEPOINT;
 JL_DLLEXPORT jl_value_t *jl_get_libllvm(void) JL_NOTSAFEPOINT;
 extern JL_DLLIMPORT int jl_n_threadpools;
-extern JL_DLLIMPORT _Atomic(int) jl_n_threads;
+extern JL_DLLIMPORT _JAtomic(int) jl_n_threads;
 extern JL_DLLIMPORT int *jl_n_threads_per_pool;
 
 // environment entries
@@ -1922,15 +1922,15 @@ typedef struct _jl_task_t {
     jl_value_t *logstate;
     jl_function_t *start;
     uint64_t rngState[4];
-    _Atomic(uint8_t) _state;
+    _JAtomic(uint8_t) _state;
     uint8_t sticky; // record whether this Task can be migrated to a new thread
-    _Atomic(uint8_t) _isexception; // set if `result` is an exception to throw or that we exited with
+    _JAtomic(uint8_t) _isexception; // set if `result` is an exception to throw or that we exited with
     // multiqueue priority
     uint16_t priority;
 
 // hidden state:
     // id of owning thread - does not need to be defined until the task runs
-    _Atomic(int16_t) tid;
+    _JAtomic(int16_t) tid;
     // threadpool id
     int8_t threadpoolid;
     // saved gc stack top for context switches
diff --git a/src/julia_atomics.h b/src/julia_atomics.h
index fea1cd2ee..312e2615b 100644
--- a/src/julia_atomics.h
+++ b/src/julia_atomics.h
@@ -33,9 +33,10 @@ using std::atomic_compare_exchange_strong_explicit;
 using std::atomic_exchange;
 using std::atomic_exchange_explicit;
 extern "C" {
-#define _Atomic(T) std::atomic<T>
+#define _JAtomic(T) std::atomic<T>
 #else
 #include <stdatomic.h>
+#define _JAtomic(T) _Atomic(T)
 #endif
 #include <signal.h> // for sig_atomic_t
 
@@ -232,8 +233,7 @@ extern "C" {
 // expressions with similar properties (for the sake of the analyzer, we don't
 // care if it is an exact match for behavior)
 
-#undef _Atomic
-#define _Atomic(T) T
+#define _JAtomic(T) T
 
 #undef jl_atomic_exchange
 #undef jl_atomic_exchange_relaxed
diff --git a/src/julia_internal.h b/src/julia_internal.h
index 15e004e0b..d3eef8173 100644
--- a/src/julia_internal.h
+++ b/src/julia_internal.h
@@ -139,7 +139,7 @@ void __tsan_switch_to_fiber(void *fiber, unsigned flags);
 // If we've smashed the stack, (and not just normal NORETURN)
 // this will smash stack-unwind too
 #ifdef _OS_WINDOWS_
-#if defined(_CPU_X86_64_)
+#if defined(_CPU_X86_64_) && !defined(_MSC_VER)
     // install the unhandled exception handler at the top of our stack
     // to call directly into our personality handler
 #define CFI_NORETURN \
@@ -174,7 +174,7 @@ extern JL_DLLEXPORT uintptr_t __stack_chk_guard;
 static uv_loop_t *const unused_uv_loop_arg = (uv_loop_t *)0xBAD10;
 
 extern jl_mutex_t jl_uv_mutex;
-extern _Atomic(int) jl_uv_n_waiters;
+extern _JAtomic(int) jl_uv_n_waiters;
 void JL_UV_LOCK(void);
 #define JL_UV_UNLOCK() JL_UNLOCK(&jl_uv_mutex)
 
@@ -203,7 +203,9 @@ JL_DLLEXPORT void jl_unlock_profile_wr(void) JL_NOTSAFEPOINT;
 // number of cycles since power-on
 static inline uint64_t cycleclock(void) JL_NOTSAFEPOINT
 {
-#if defined(_CPU_X86_64_)
+#ifdef _MSC_VER
+  return __rdtsc(); 
+#elif defined(_CPU_X86_64_)
     uint64_t low, high;
     __asm__ volatile("rdtsc" : "=a"(low), "=d"(high));
     return (high << 32) | low;
@@ -255,9 +257,9 @@ static inline uint64_t cycleclock(void) JL_NOTSAFEPOINT
 #include "timing.h"
 
 // Global *atomic* integers controlling *process-wide* measurement of compilation time.
-extern JL_DLLEXPORT _Atomic(uint8_t) jl_measure_compile_time_enabled;
-extern JL_DLLEXPORT _Atomic(uint64_t) jl_cumulative_compile_time;
-extern JL_DLLEXPORT _Atomic(uint64_t) jl_cumulative_recompile_time;
+extern JL_DLLEXPORT _JAtomic(uint8_t) jl_measure_compile_time_enabled;
+extern JL_DLLEXPORT _JAtomic(uint64_t) jl_cumulative_compile_time;
+extern JL_DLLEXPORT _JAtomic(uint64_t) jl_cumulative_recompile_time;
 
 #define jl_return_address() ((uintptr_t)__builtin_return_address(0))
 
@@ -281,8 +283,8 @@ STATIC_INLINE uint32_t jl_int32hash_fast(uint32_t a)
 static inline void memmove_refs(void **dstp, void *const *srcp, size_t n) JL_NOTSAFEPOINT
 {
     size_t i;
-    _Atomic(void*) *srcpa = (_Atomic(void*)*)srcp;
-    _Atomic(void*) *dstpa = (_Atomic(void*)*)dstp;
+    _JAtomic(void*) *srcpa = (_JAtomic(void*)*)srcp;
+    _JAtomic(void*) *dstpa = (_JAtomic(void*)*)dstp;
     if (dstp < srcp || dstp > srcp + n) {
         for (i = 0; i < n; i++) {
             jl_atomic_store_release(dstpa + i, jl_atomic_load_relaxed(srcpa + i));
@@ -307,7 +309,7 @@ static inline void memmove_refs(void **dstp, void *const *srcp, size_t n) JL_NOT
 extern jl_methtable_t *jl_type_type_mt JL_GLOBALLY_ROOTED;
 extern jl_methtable_t *jl_nonfunction_mt JL_GLOBALLY_ROOTED;
 extern jl_methtable_t *jl_kwcall_mt JL_GLOBALLY_ROOTED;
-extern JL_DLLEXPORT _Atomic(size_t) jl_world_counter;
+extern JL_DLLEXPORT _JAtomic(size_t) jl_world_counter;
 
 typedef void (*tracer_cb)(jl_value_t *tracee);
 extern tracer_cb jl_newmeth_tracer;
@@ -320,7 +322,7 @@ JL_DLLEXPORT extern arraylist_t jl_image_relocs;  // external linkage: sysimg/pk
 extern JL_DLLEXPORT size_t jl_page_size;
 extern jl_function_t *jl_typeinf_func JL_GLOBALLY_ROOTED;
 extern JL_DLLEXPORT size_t jl_typeinf_world;
-extern _Atomic(jl_typemap_entry_t*) call_cache[N_CALL_CACHE] JL_GLOBALLY_ROOTED;
+extern _JAtomic(jl_typemap_entry_t*) call_cache[N_CALL_CACHE] JL_GLOBALLY_ROOTED;
 extern jl_array_t *jl_all_methods JL_GLOBALLY_ROOTED;
 
 JL_DLLEXPORT extern int jl_lineno;
@@ -889,7 +891,7 @@ STATIC_INLINE int jl_addr_is_safepoint(uintptr_t addr)
     uintptr_t safepoint_addr = (uintptr_t)jl_safepoint_pages;
     return addr >= safepoint_addr && addr < safepoint_addr + jl_page_size * 3;
 }
-extern _Atomic(uint32_t) jl_gc_running;
+extern _JAtomic(uint32_t) jl_gc_running;
 // All the functions are safe to be called from within a signal handler
 // provided that the thread will not be interrupted by another asynchronous
 // signal.
@@ -987,7 +989,7 @@ JL_DLLEXPORT void jl_get_function_id(void *native_code, jl_code_instance_t *ncod
 // the first argument to jl_idtable_rehash is used to return a value
 // make sure it is rooted if it is used after the function returns
 JL_DLLEXPORT jl_array_t *jl_idtable_rehash(jl_array_t *a, size_t newsz);
-_Atomic(jl_value_t*) *jl_table_peek_bp(jl_array_t *a, jl_value_t *key) JL_NOTSAFEPOINT;
+_JAtomic(jl_value_t*) *jl_table_peek_bp(jl_array_t *a, jl_value_t *key) JL_NOTSAFEPOINT;
 
 JL_DLLEXPORT jl_method_t *jl_new_method_uninit(jl_module_t*);
 
@@ -1272,7 +1274,7 @@ void win32_formatmessage(DWORD code, char *reason, int len) JL_NOTSAFEPOINT;
 
 JL_DLLEXPORT void *jl_get_library_(const char *f_lib, int throw_err);
 #define jl_get_library(f_lib) jl_get_library_(f_lib, 1)
-JL_DLLEXPORT void *jl_load_and_lookup(const char *f_lib, const char *f_name, _Atomic(void*) *hnd);
+JL_DLLEXPORT void *jl_load_and_lookup(const char *f_lib, const char *f_name, _JAtomic(void*) *hnd);
 JL_DLLEXPORT void *jl_lazy_load_and_lookup(jl_value_t *lib_val, const char *f_name);
 JL_DLLEXPORT jl_value_t *jl_get_cfunction_trampoline(
     jl_value_t *fobj, jl_datatype_t *result, htable_t *cache, jl_svec_t *fill,
@@ -1411,11 +1413,11 @@ void jl_mach_gc_end(void);
 typedef uint_t (*smallintset_hash)(size_t val, jl_svec_t *data);
 typedef int (*smallintset_eq)(size_t val, const void *key, jl_svec_t *data, uint_t hv);
 ssize_t jl_smallintset_lookup(jl_array_t *cache, smallintset_eq eq, const void *key, jl_svec_t *data, uint_t hv);
-void jl_smallintset_insert(_Atomic(jl_array_t*) *pcache, jl_value_t *parent, smallintset_hash hash, size_t val, jl_svec_t *data);
+void jl_smallintset_insert(_JAtomic(jl_array_t*) *pcache, jl_value_t *parent, smallintset_hash hash, size_t val, jl_svec_t *data);
 
 // -- typemap.c -- //
 
-void jl_typemap_insert(_Atomic(jl_typemap_t*) *cache, jl_value_t *parent,
+void jl_typemap_insert(_JAtomic(jl_typemap_t*) *cache, jl_value_t *parent,
         jl_typemap_entry_t *newrec, int8_t offs);
 jl_typemap_entry_t *jl_typemap_alloc(
         jl_tupletype_t *type, jl_tupletype_t *simpletype, jl_svec_t *guardsigs,
diff --git a/src/julia_threads.h b/src/julia_threads.h
index 847465b36..de1711917 100644
--- a/src/julia_threads.h
+++ b/src/julia_threads.h
@@ -48,7 +48,7 @@ typedef struct {
     !defined(JL_HAVE_ASYNCIFY)
 #if (defined(_CPU_X86_64_) || defined(_CPU_X86_) || defined(_CPU_AARCH64_) ||  \
      defined(_CPU_ARM_) || defined(_CPU_PPC64_))
-#define JL_HAVE_ASM
+//#define JL_HAVE_ASM
 #endif
 #if 0
 // very slow, but more debugging
@@ -115,7 +115,7 @@ struct _jl_task_t;
 
 // Recursive spin lock
 typedef struct {
-    _Atomic(struct _jl_task_t*) owner;
+    _JAtomic(struct _jl_task_t*) owner;
     uint32_t count;
 } jl_mutex_t;
 
@@ -126,13 +126,13 @@ typedef struct {
 } jl_gc_pool_t;
 
 typedef struct {
-    _Atomic(int64_t) allocd;
-    _Atomic(int64_t) freed;
-    _Atomic(uint64_t) malloc;
-    _Atomic(uint64_t) realloc;
-    _Atomic(uint64_t) poolalloc;
-    _Atomic(uint64_t) bigalloc;
-    _Atomic(uint64_t) freecall;
+    _JAtomic(int64_t) allocd;
+    _JAtomic(int64_t) freed;
+    _JAtomic(uint64_t) malloc;
+    _JAtomic(uint64_t) realloc;
+    _JAtomic(uint64_t) poolalloc;
+    _JAtomic(uint64_t) bigalloc;
+    _JAtomic(uint64_t) freecall;
 } jl_thread_gc_num_t;
 
 typedef struct {
@@ -213,7 +213,7 @@ typedef struct _jl_tls_states_t {
     int8_t threadpoolid;
     uint64_t rngseed;
     volatile size_t *safepoint;
-    _Atomic(int8_t) sleep_check_state; // read/write from foreign threads
+    _JAtomic(int8_t) sleep_check_state; // read/write from foreign threads
     // Whether it is safe to execute GC at the same time.
 #define JL_GC_STATE_WAITING 1
     // gc_state = 1 means the thread is doing GC or is waiting for the GC to
@@ -221,7 +221,7 @@ typedef struct _jl_tls_states_t {
 #define JL_GC_STATE_SAFE 2
     // gc_state = 2 means the thread is running unmanaged code that can be
     //              execute at the same time with the GC.
-    _Atomic(int8_t) gc_state; // read from foreign threads
+    _JAtomic(int8_t) gc_state; // read from foreign threads
     // execution of certain certain impure
     // statements is prohibited from certain
     // callbacks (such as generated functions)
@@ -234,7 +234,7 @@ typedef struct _jl_tls_states_t {
     jl_thread_heap_t heap; // this is very large, and the offset is baked into codegen
     jl_thread_gc_num_t gc_num;
     volatile sig_atomic_t defer_signal;
-    _Atomic(struct _jl_task_t*) current_task;
+    _JAtomic(struct _jl_task_t*) current_task;
     struct _jl_task_t *next_task;
     struct _jl_task_t *previous_task;
     struct _jl_task_t *root_task;
@@ -254,7 +254,7 @@ typedef struct _jl_tls_states_t {
     // Temporary backtrace buffer used only for allocations profiler.
     struct _jl_bt_element_t *profiling_bt_buffer;
     // Atomically set by the sender, reset by the handler.
-    volatile _Atomic(sig_atomic_t) signal_request; // TODO: no actual reason for this to be _Atomic
+    volatile _JAtomic(sig_atomic_t) signal_request; // TODO: no actual reason for this to be _Atomic
     // Allow the sigint to be raised asynchronously
     // this is limited to the few places we do synchronous IO
     // we can make this more general (similar to defer_signal) if necessary
@@ -370,7 +370,7 @@ JL_DLLEXPORT void jl_gc_enable_finalizers(struct _jl_task_t *ct, int on);
 JL_DLLEXPORT void jl_gc_disable_finalizers_internal(void);
 JL_DLLEXPORT void jl_gc_enable_finalizers_internal(void);
 JL_DLLEXPORT void jl_gc_run_pending_finalizers(struct _jl_task_t *ct);
-extern JL_DLLEXPORT _Atomic(int) jl_gc_have_pending_finalizers;
+extern JL_DLLEXPORT _JAtomic(int) jl_gc_have_pending_finalizers;
 
 JL_DLLEXPORT void jl_wakeup_thread(int16_t tid);
 
diff --git a/src/method.c b/src/method.c
index 4e48ef912..b5bc3fa8d 100644
--- a/src/method.c
+++ b/src/method.c
@@ -882,7 +882,7 @@ jl_method_t *jl_make_opaque_closure_method(jl_module_t *module, jl_value_t *name
 // empty generic function def
 JL_DLLEXPORT jl_value_t *jl_generic_function_def(jl_sym_t *name,
                                                  jl_module_t *module,
-                                                 _Atomic(jl_value_t*) *bp,
+                                                 _JAtomic(jl_value_t*) *bp,
                                                  jl_value_t *bp_owner,
                                                  jl_binding_t *bnd)
 {
diff --git a/src/partr.c b/src/partr.c
index aceaf9dc2..4845982f4 100644
--- a/src/partr.c
+++ b/src/partr.c
@@ -138,7 +138,7 @@ int jl_running_under_rr(int recheck)
 #ifdef _OS_LINUX_
 #define RR_CALL_BASE 1000
 #define SYS_rrcall_check_presence (RR_CALL_BASE + 8)
-    static _Atomic(int) is_running_under_rr = 0;
+    static _JAtomic(int) is_running_under_rr = 0;
     int rr = jl_atomic_load_relaxed(&is_running_under_rr);
     if (rr == 0 || recheck) {
         int ret = syscall(SYS_rrcall_check_presence, 0, 0, 0, 0, 0, 0);
@@ -291,7 +291,7 @@ static int may_sleep(jl_ptls_t ptls) JL_NOTSAFEPOINT
     return jl_atomic_load_relaxed(&ptls->sleep_check_state) == sleeping;
 }
 
-extern _Atomic(unsigned) _threadedregion;
+extern _JAtomic(unsigned) _threadedregion;
 
 JL_DLLEXPORT jl_task_t *jl_task_get_next(jl_value_t *trypoptask, jl_value_t *q, jl_value_t *checkempty)
 {
diff --git a/src/pipeline.cpp b/src/pipeline.cpp
index 10709989f..d8db79eae 100644
--- a/src/pipeline.cpp
+++ b/src/pipeline.cpp
@@ -711,7 +711,7 @@ void registerCallbacks(PassBuilder &PB) {
         });
 }
 
-extern "C" JL_DLLEXPORT ::llvm::PassPluginLibraryInfo
+extern "C" ::llvm::PassPluginLibraryInfo
 llvmGetPassPluginInfo() {
       return {LLVM_PLUGIN_API_VERSION, "Julia", "1", registerCallbacks};
 }
diff --git a/src/processor.h b/src/processor.h
index d1b18cb72..e962a1d40 100644
--- a/src/processor.h
+++ b/src/processor.h
@@ -194,14 +194,14 @@ extern JL_DLLEXPORT bool jl_processor_print_help;
  * If the detected/specified CPU name is not available on the LLVM version specified,
  * a fallback CPU name will be used. Unsupported features will be ignored.
  */
-extern "C" JL_DLLEXPORT std::pair<std::string,std::vector<std::string>> jl_get_llvm_target(bool imaging, uint32_t &flags);
+JL_DLLEXPORT std::pair<std::string,std::vector<std::string>> jl_get_llvm_target(bool imaging, uint32_t &flags);
 
 /**
  * Returns the CPU name and feature string to be used by LLVM disassembler.
  *
  * This will return a generic CPU name and a full feature string.
  */
-extern "C" JL_DLLEXPORT const std::pair<std::string,std::string> &jl_get_llvm_disasm_target(void);
+JL_DLLEXPORT const std::pair<std::string,std::string> &jl_get_llvm_disasm_target(void);
 
 struct jl_target_spec_t {
     // LLVM target name
@@ -218,7 +218,7 @@ struct jl_target_spec_t {
 /**
  * Return the list of targets to clone
  */
-extern "C" JL_DLLEXPORT std::vector<jl_target_spec_t> jl_get_llvm_clone_targets(void);
+JL_DLLEXPORT std::vector<jl_target_spec_t> jl_get_llvm_clone_targets(void);
 std::string jl_get_cpu_name_llvm(void);
 std::string jl_get_cpu_features_llvm(void);
 #endif
diff --git a/src/runtime_ccall.cpp b/src/runtime_ccall.cpp
index e3543c9f6..bf8cf7602 100644
--- a/src/runtime_ccall.cpp
+++ b/src/runtime_ccall.cpp
@@ -54,7 +54,7 @@ void *jl_get_library_(const char *f_lib, int throw_err)
 }
 
 extern "C" JL_DLLEXPORT
-void *jl_load_and_lookup(const char *f_lib, const char *f_name, _Atomic(void*) *hnd)
+void *jl_load_and_lookup(const char *f_lib, const char *f_name, _JAtomic(void*) *hnd)
 {
     void *handle = jl_atomic_load_acquire(hnd);
     if (!handle)
diff --git a/src/runtime_intrinsics.c b/src/runtime_intrinsics.c
index a170c81c6..74b9ad98e 100644
--- a/src/runtime_intrinsics.c
+++ b/src/runtime_intrinsics.c
@@ -306,7 +306,7 @@ JL_DLLEXPORT jl_value_t *jl_atomic_pointerref(jl_value_t *p, jl_value_t *order)
     jl_value_t *ety = jl_tparam0(jl_typeof(p));
     char *pp = (char*)jl_unbox_long(p);
     if (ety == (jl_value_t*)jl_any_type) {
-        return jl_atomic_load((_Atomic(jl_value_t*)*)pp);
+        return jl_atomic_load((_JAtomic(jl_value_t*)*)pp);
     }
     else {
         if (!is_valid_intrinsic_elptr(ety))
@@ -326,7 +326,7 @@ JL_DLLEXPORT jl_value_t *jl_atomic_pointerset(jl_value_t *p, jl_value_t *x, jl_v
     jl_value_t *ety = jl_tparam0(jl_typeof(p));
     char *pp = (char*)jl_unbox_long(p);
     if (ety == (jl_value_t*)jl_any_type) {
-        jl_atomic_store((_Atomic(jl_value_t*)*)pp, x);
+        jl_atomic_store((_JAtomic(jl_value_t*)*)pp, x);
     }
     else {
         if (!is_valid_intrinsic_elptr(ety))
@@ -350,7 +350,7 @@ JL_DLLEXPORT jl_value_t *jl_atomic_pointerswap(jl_value_t *p, jl_value_t *x, jl_
     jl_value_t *y;
     char *pp = (char*)jl_unbox_long(p);
     if (ety == (jl_value_t*)jl_any_type) {
-        y = jl_atomic_exchange((_Atomic(jl_value_t*)*)pp, x);
+        y = jl_atomic_exchange((_JAtomic(jl_value_t*)*)pp, x);
     }
     else {
         if (!is_valid_intrinsic_elptr(ety))
@@ -374,7 +374,7 @@ JL_DLLEXPORT jl_value_t *jl_atomic_pointermodify(jl_value_t *p, jl_value_t *f, j
     char *pp = (char*)jl_unbox_long(p);
     jl_value_t *expected;
     if (ety == (jl_value_t*)jl_any_type) {
-        expected = jl_atomic_load((_Atomic(jl_value_t*)*)pp);
+        expected = jl_atomic_load((_JAtomic(jl_value_t*)*)pp);
     }
     else {
         if (!is_valid_intrinsic_elptr(ety))
@@ -392,7 +392,7 @@ JL_DLLEXPORT jl_value_t *jl_atomic_pointermodify(jl_value_t *p, jl_value_t *f, j
         jl_value_t *y = jl_apply_generic(f, args, 2);
         args[1] = y;
         if (ety == (jl_value_t*)jl_any_type) {
-            if (jl_atomic_cmpswap((_Atomic(jl_value_t*)*)pp, &expected, y))
+            if (jl_atomic_cmpswap((_JAtomic(jl_value_t*)*)pp, &expected, y))
                 break;
         }
         else {
@@ -438,7 +438,7 @@ JL_DLLEXPORT jl_value_t *jl_atomic_pointerreplace(jl_value_t *p, jl_value_t *exp
         result = expected;
         int success;
         while (1) {
-            success = jl_atomic_cmpswap((_Atomic(jl_value_t*)*)pp, &result, x);
+            success = jl_atomic_cmpswap((_JAtomic(jl_value_t*)*)pp, &result, x);
             if (success || !jl_egal(result, expected))
                 break;
         }
diff --git a/src/safepoint.c b/src/safepoint.c
index 1ff26d616..70e4b7c87 100644
--- a/src/safepoint.c
+++ b/src/safepoint.c
@@ -19,7 +19,7 @@ extern "C" {
 // 1: at least one sigint is pending, only the sigint page is enabled.
 // 2: at least one sigint is pending, both safepoint pages are enabled.
 JL_DLLEXPORT sig_atomic_t jl_signal_pending = 0;
-_Atomic(uint32_t) jl_gc_running = 0;
+_JAtomic(uint32_t) jl_gc_running = 0;
 char *jl_safepoint_pages = NULL;
 // The number of safepoints enabled on the three pages.
 // The first page, is the SIGINT page, only used by the master thread.
diff --git a/src/smallintset.c b/src/smallintset.c
index 54fdad616..caaea620f 100644
--- a/src/smallintset.c
+++ b/src/smallintset.c
@@ -130,9 +130,9 @@ static int smallintset_insert_(jl_array_t *a, uint_t hv, size_t val1)
     return 0;
 }
 
-static void smallintset_rehash(_Atomic(jl_array_t*) *pcache, jl_value_t *parent, smallintset_hash hash, jl_svec_t *data, size_t newsz, size_t np);
+static void smallintset_rehash(_JAtomic(jl_array_t*) *pcache, jl_value_t *parent, smallintset_hash hash, jl_svec_t *data, size_t newsz, size_t np);
 
-void jl_smallintset_insert(_Atomic(jl_array_t*) *pcache, jl_value_t *parent, smallintset_hash hash, size_t val, jl_svec_t *data)
+void jl_smallintset_insert(_JAtomic(jl_array_t*) *pcache, jl_value_t *parent, smallintset_hash hash, size_t val, jl_svec_t *data)
 {
     jl_array_t *a = jl_atomic_load_relaxed(pcache);
     if (val + 1 >  jl_max_int(a))
@@ -159,7 +159,7 @@ void jl_smallintset_insert(_Atomic(jl_array_t*) *pcache, jl_value_t *parent, sma
     }
 }
 
-static void smallintset_rehash(_Atomic(jl_array_t*) *pcache, jl_value_t *parent, smallintset_hash hash, jl_svec_t *data, size_t newsz, size_t np)
+static void smallintset_rehash(_JAtomic(jl_array_t*) *pcache, jl_value_t *parent, smallintset_hash hash, jl_svec_t *data, size_t newsz, size_t np)
 {
     jl_array_t *a = jl_atomic_load_relaxed(pcache);
     size_t sz = jl_array_len(a);
diff --git a/src/support/Makefile b/src/support/Makefile
index f52ca8eaf..3db671e58 100644
--- a/src/support/Makefile
+++ b/src/support/Makefile
@@ -1,4 +1,6 @@
 SRCDIR := $(abspath $(dir $(lastword $(MAKEFILE_LIST))))
+$(info SRCDIR is $(SRCDIR))
+
 JULIAHOME := $(abspath $(SRCDIR)/../..)
 BUILDDIR := .
 include $(JULIAHOME)/Make.inc
@@ -7,7 +9,7 @@ JCFLAGS += $(CFLAGS)
 JCXXFLAGS += $(CXXFLAGS)
 JCPPFLAGS += $(CPPFLAGS)
 JLDFLAGS += $(LDFLAGS)
-
+ARCH := x86_64
 SRCS := hashing timefuncs ptrhash operators utf8 ios htable bitvector \
 	int2str libsupportinit arraylist strtod rle
 ifeq ($(OS),WINNT)
@@ -19,12 +21,15 @@ SRCS += _setjmp.win64
 endif
 endif
 
-HEADERS := $(wildcard *.h) $(LIBUV_INC)/uv.h
+HEADERS := $(wildcard *.h)
+# $(LIBUV_INC)/uv.h
 
 OBJS := $(SRCS:%=$(BUILDDIR)/%.o)
 DOBJS := $(SRCS:%=$(BUILDDIR)/%.dbg.obj)
 
-FLAGS := $(HFILEDIRS:%=-I%) -I$(LIBUV_INC) -I$(UTF8PROC_INC) -DLIBRARY_EXPORTS -DUTF8PROC_EXPORTS
+FLAGS := $(HFILEDIRS:%=-I%) -DLIBRARY_EXPORTS 
+#-DUTF8PROC_EXPORTS
+#-I$(LIBUV_INC) -I$(UTF8PROC_INC)
 #FLAGS += -Wall -Wno-strict-aliasing -fvisibility=hidden -Wpointer-arith -Wundef
 #JCFLAGS += -Wold-style-definition -Wstrict-prototypes -Wc++-compat
 
@@ -36,14 +41,17 @@ default: release
 $(BUILDDIR):
 	mkdir -p $(BUILDDIR)
 
+$(info BUILDDIR is $(BUILDDIR))
+$(info HEADERS is $(HEADERS))
+
 $(BUILDDIR)/%.o: $(SRCDIR)/%.c $(HEADERS) | $(BUILDDIR)
 	@$(call PRINT_CC, $(CC) $(JCPPFLAGS) $(JCFLAGS) $(SHIPFLAGS) $(DISABLE_ASSERTIONS) -c $< -o $@)
 $(BUILDDIR)/%.dbg.obj: $(SRCDIR)/%.c $(HEADERS) | $(BUILDDIR)
 	@$(call PRINT_CC, $(CC) $(JCPPFLAGS) $(JCFLAGS) $(DEBUGFLAGS) -c $< -o $@)
 $(BUILDDIR)/%.o: $(SRCDIR)/%.S | $(BUILDDIR)
-	@$(call PRINT_CC, $(CC) $(JCPPFLAGS) $(SHIPFLAGS) -c $< -o $@)
+	@$(call PRINT_CC, $(CCAS) $(JCPPFLAGS) $(SHIPFLAGS) -c $< -o $@)
 $(BUILDDIR)/%.dbg.obj: $(SRCDIR)/%.S | $(BUILDDIR)
-	@$(call PRINT_CC, $(CC) $(JCPPFLAGS) $(DEBUGFLAGS) -c $< -o $@)
+	@$(call PRINT_CC, $(CCAS) $(JCPPFLAGS) $(DEBUGFLAGS) -c $< -o $@)
 
 $(BUILDDIR)/host/Makefile:
 	mkdir -p $(BUILDDIR)/host
diff --git a/src/support/dtypes.h b/src/support/dtypes.h
index d49ae0b22..0e28a373c 100644
--- a/src/support/dtypes.h
+++ b/src/support/dtypes.h
@@ -25,6 +25,7 @@
 #include <stdlib.h>
 #include <sys/stat.h>
 #define WIN32_LEAN_AND_MEAN
+#define NOMINMAX
 #include <windows.h>
 
 #if defined(_COMPILER_MICROSOFT_) && !defined(_SSIZE_T_) && !defined(_SSIZE_T_DEFINED)
diff --git a/src/support/platform.h b/src/support/platform.h
index 56f8cafbc..7a07cd449 100644
--- a/src/support/platform.h
+++ b/src/support/platform.h
@@ -33,7 +33,7 @@
 *                               Compiler                                       *
 *******************************************************************************/
 
-#if defined(__clang__)
+#if defined(__clang__) && !defined(_MSC_VER)
 #define _COMPILER_CLANG_
 #elif defined(__GNUC__)
 #define _COMPILER_GCC_
diff --git a/src/symbol.c b/src/symbol.c
index 14606c82b..49bbf5283 100644
--- a/src/symbol.c
+++ b/src/symbol.c
@@ -15,7 +15,7 @@
 extern "C" {
 #endif
 
-static _Atomic(jl_sym_t*) symtab = NULL;
+static _JAtomic(jl_sym_t*) symtab = NULL;
 
 #define MAX_SYM_LEN ((size_t)INTPTR_MAX - sizeof(jl_taggedvalue_t) - sizeof(jl_sym_t) - 1)
 
@@ -49,7 +49,7 @@ static jl_sym_t *mk_symbol(const char *str, size_t len) JL_NOTSAFEPOINT
     return sym;
 }
 
-static jl_sym_t *symtab_lookup(_Atomic(jl_sym_t*) *ptree, const char *str, size_t len, _Atomic(jl_sym_t*) **slot) JL_NOTSAFEPOINT
+static jl_sym_t *symtab_lookup(_JAtomic(jl_sym_t*) *ptree, const char *str, size_t len, _JAtomic(jl_sym_t*) **slot) JL_NOTSAFEPOINT
 {
     jl_sym_t *node = jl_atomic_load_relaxed(ptree); // consume
     uintptr_t h = hash_symbol(str, len);
@@ -85,7 +85,7 @@ jl_sym_t *_jl_symbol(const char *str, size_t len) JL_NOTSAFEPOINT // (or throw)
         jl_exceptionf(jl_argumenterror_type, "Symbol name too long");
 #endif
     assert(!memchr(str, 0, len));
-    _Atomic(jl_sym_t*) *slot;
+    _JAtomic(jl_sym_t*) *slot;
     jl_sym_t *node = symtab_lookup(&symtab, str, len, &slot);
     if (node == NULL) {
         uv_mutex_lock(&gc_perm_lock);
@@ -123,7 +123,7 @@ JL_DLLEXPORT jl_sym_t *jl_get_root_symbol(void)
     return jl_atomic_load_relaxed(&symtab);
 }
 
-static _Atomic(uint32_t) gs_ctr = 0;  // TODO: per-module?
+static _JAtomic(uint32_t) gs_ctr = 0;  // TODO: per-module?
 uint32_t jl_get_gs_ctr(void) { return jl_atomic_load_relaxed(&gs_ctr); }
 void jl_set_gs_ctr(uint32_t ctr) { jl_atomic_store_relaxed(&gs_ctr, ctr); }
 
diff --git a/src/sys.c b/src/sys.c
index 2de4bc61a..880db7ffa 100644
--- a/src/sys.c
+++ b/src/sys.c
@@ -140,7 +140,7 @@ JL_DLLEXPORT int32_t jl_fstat(uv_os_fd_t fd, char *statbuf)
     uv_fs_t req;
     int ret;
 
-    ret = uv_fs_fstat(unused_uv_loop_arg, &req, fd, NULL);
+    ret = uv_fs_fstat(unused_uv_loop_arg, &req, (int)fd, NULL);
     if (ret == 0)
         memcpy(statbuf, req.ptr, sizeof(uv_stat_t));
     uv_fs_req_cleanup(&req);
@@ -728,7 +728,7 @@ JL_DLLEXPORT size_t jl_maxrss(void)
 
 // Simple `rand()` like function, with global seed and added thread-safety
 // (but slow and insecure)
-static _Atomic(uint64_t) g_rngseed;
+static _JAtomic(uint64_t) g_rngseed;
 JL_DLLEXPORT uint64_t jl_rand(void) JL_NOTSAFEPOINT
 {
     uint64_t max = UINT64_MAX;
diff --git a/src/task.c b/src/task.c
index 4bb5d666a..699075d5d 100644
--- a/src/task.c
+++ b/src/task.c
@@ -29,7 +29,9 @@
 #include <stdlib.h>
 #include <string.h>
 #include <signal.h>
+#ifndef _MSC_VER
 #include <unistd.h>
+#endif
 #include <errno.h>
 #include <inttypes.h>
 #include "julia.h"
@@ -288,7 +290,7 @@ JL_NO_ASAN static void restore_stack2(jl_task_t *t, jl_ptls_t ptls, jl_task_t *l
 #endif
 
 /* Rooted by the base module */
-static _Atomic(jl_function_t*) task_done_hook_func JL_GLOBALLY_ROOTED = NULL;
+static _JAtomic(jl_function_t*) task_done_hook_func JL_GLOBALLY_ROOTED = NULL;
 
 void JL_NORETURN jl_finish_task(jl_task_t *t)
 {
diff --git a/src/threading.c b/src/threading.c
index f81924ab9..0c159718b 100644
--- a/src/threading.c
+++ b/src/threading.c
@@ -36,9 +36,9 @@ extern "C" {
 
 #include "threading.h"
 
-JL_DLLEXPORT _Atomic(uint8_t) jl_measure_compile_time_enabled = 0;
-JL_DLLEXPORT _Atomic(uint64_t) jl_cumulative_compile_time = 0;
-JL_DLLEXPORT _Atomic(uint64_t) jl_cumulative_recompile_time = 0;
+JL_DLLEXPORT _JAtomic(uint8_t) jl_measure_compile_time_enabled = 0;
+JL_DLLEXPORT _JAtomic(uint64_t) jl_cumulative_compile_time = 0;
+JL_DLLEXPORT _JAtomic(uint64_t) jl_cumulative_recompile_time = 0;
 
 JL_DLLEXPORT void *jl_get_ptls_states(void)
 {
@@ -302,7 +302,7 @@ void jl_pgcstack_getkey(jl_get_pgcstack_func **f, jl_pgcstack_key_t *k)
 #endif
 
 static uv_mutex_t tls_lock; // controls write-access to these variables:
-_Atomic(jl_ptls_t*) jl_all_tls_states JL_GLOBALLY_ROOTED;
+_JAtomic(jl_ptls_t*) jl_all_tls_states JL_GLOBALLY_ROOTED;
 int jl_all_tls_states_size;
 static uv_cond_t cond;
 
@@ -666,7 +666,7 @@ void jl_start_threads(void)
     uv_barrier_wait(&thread_init_done);
 }
 
-_Atomic(unsigned) _threadedregion; // HACK: keep track of whether to prioritize IO or threading
+_JAtomic(unsigned) _threadedregion; // HACK: keep track of whether to prioritize IO or threading
 
 JL_DLLEXPORT int jl_in_threaded_region(void)
 {
diff --git a/src/threading.h b/src/threading.h
index 9fd63f0fd..2457d70f2 100644
--- a/src/threading.h
+++ b/src/threading.h
@@ -12,7 +12,7 @@ extern "C" {
 
 #define PROFILE_JL_THREADING            0
 
-extern _Atomic(jl_ptls_t*) jl_all_tls_states JL_GLOBALLY_ROOTED; /* thread local storage */
+extern _JAtomic(jl_ptls_t*) jl_all_tls_states JL_GLOBALLY_ROOTED; /* thread local storage */
 
 typedef struct _jl_threadarg_t {
     int16_t tid;
diff --git a/src/typemap.c b/src/typemap.c
index 3afa1ffc1..6dbd808f8 100644
--- a/src/typemap.c
+++ b/src/typemap.c
@@ -259,16 +259,16 @@ static int is_cache_leaf(jl_value_t *ty, int tparam)
     return (jl_is_concrete_type(ty) && (tparam || !jl_is_kind(ty)));
 }
 
-static _Atomic(jl_typemap_t*) *mtcache_hash_lookup_bp(jl_array_t *cache JL_PROPAGATES_ROOT, jl_value_t *ty) JL_NOTSAFEPOINT
+static _JAtomic(jl_typemap_t*) *mtcache_hash_lookup_bp(jl_array_t *cache JL_PROPAGATES_ROOT, jl_value_t *ty) JL_NOTSAFEPOINT
 {
     if (cache == (jl_array_t*)jl_an_empty_vec_any)
         return NULL;
-    _Atomic(jl_typemap_t*) *pml = jl_table_peek_bp(cache, ty);
+    _JAtomic(jl_typemap_t*) *pml = jl_table_peek_bp(cache, ty);
     JL_GC_PROMISE_ROOTED(pml); // clang-sa doesn't trust our JL_PROPAGATES_ROOT claim
     return pml;
 }
 
-static void mtcache_hash_insert(_Atomic(jl_array_t*) *cache, jl_value_t *parent, jl_value_t *key, jl_typemap_t *val)
+static void mtcache_hash_insert(_JAtomic(jl_array_t*) *cache, jl_value_t *parent, jl_value_t *key, jl_typemap_t *val)
 {
     int inserted = 0;
     jl_array_t *a = jl_atomic_load_relaxed(cache);
@@ -298,7 +298,7 @@ static jl_typemap_t *mtcache_hash_lookup(jl_array_t *cache JL_PROPAGATES_ROOT, j
 static int jl_typemap_array_visitor(jl_array_t *a, jl_typemap_visitor_fptr fptr, void *closure)
 {
     size_t i, l = jl_array_len(a);
-    _Atomic(jl_typemap_t*) *data = (_Atomic(jl_typemap_t*)*)jl_array_data(a);
+    _JAtomic(jl_typemap_t*) *data = (_JAtomic(jl_typemap_t*)*)jl_array_data(a);
     for (i = 1; i < l; i += 2) {
         jl_value_t *d = jl_atomic_load_relaxed(&data[i]);
         JL_GC_PROMISE_ROOTED(d);
@@ -392,7 +392,7 @@ static int jl_typemap_intersection_array_visitor(jl_array_t *a, jl_value_t *ty,
 {
     JL_GC_PUSH1(&a);
     size_t i, l = jl_array_len(a);
-    _Atomic(jl_typemap_t*) *data = (_Atomic(jl_typemap_t*)*)jl_array_data(a);
+    _JAtomic(jl_typemap_t*) *data = (_JAtomic(jl_typemap_t*)*)jl_array_data(a);
     unsigned height = tparam & 2 ? jl_supertype_height((jl_datatype_t*)ty) : 0;
     for (i = 0; i < l; i += 2) {
         jl_value_t *t = jl_atomic_load_relaxed(&data[i]);
@@ -843,7 +843,7 @@ jl_typemap_entry_t *jl_typemap_assoc_by_type(
                     if (!ty || !jl_has_empty_intersection((jl_value_t*)jl_type_type, ty)) {
                         // couldn't figure out unique `a0` initial point, so scan all for matches
                         size_t i, l = jl_array_len(tname);
-                        _Atomic(jl_typemap_t*) *data = (_Atomic(jl_typemap_t*)*)jl_array_ptr_data(tname);
+                        _JAtomic(jl_typemap_t*) *data = (_JAtomic(jl_typemap_t*)*)jl_array_ptr_data(tname);
                         JL_GC_PUSH1(&tname);
                         for (i = 1; i < l; i += 2) {
                             jl_typemap_t *ml = jl_atomic_load_relaxed(&data[i]);
@@ -882,7 +882,7 @@ jl_typemap_entry_t *jl_typemap_assoc_by_type(
                 else {
                     // doing subtype, but couldn't figure out unique `ty`, so scan all for supertypes
                     size_t i, l = jl_array_len(name1);
-                    _Atomic(jl_typemap_t*) *data = (_Atomic(jl_typemap_t*)*)jl_array_ptr_data(name1);
+                    _JAtomic(jl_typemap_t*) *data = (_JAtomic(jl_typemap_t*)*)jl_array_ptr_data(name1);
                     JL_GC_PUSH1(&name1);
                     for (i = 1; i < l; i += 2) {
                         jl_typemap_t *ml = jl_atomic_load_relaxed(&data[i]);
@@ -1032,7 +1032,7 @@ jl_typemap_entry_t *jl_typemap_level_assoc_exact(jl_typemap_level_t *cache, jl_v
             else {
                 // couldn't figure out unique `name` initial point, so must scan all for matches
                 size_t i, l = jl_array_len(tname);
-                _Atomic(jl_typemap_t*) *data = (_Atomic(jl_typemap_t*)*)jl_array_ptr_data(tname);
+                _JAtomic(jl_typemap_t*) *data = (_JAtomic(jl_typemap_t*)*)jl_array_ptr_data(tname);
                 JL_GC_PUSH1(&tname);
                 for (i = 1; i < l; i += 2) {
                     jl_typemap_t *ml_or_cache = jl_atomic_load_relaxed(&data[i]);
@@ -1121,7 +1121,7 @@ static jl_typemap_level_t *jl_method_convert_list_to_cache(
 }
 
 static void jl_typemap_list_insert_(
-        jl_typemap_t *map, _Atomic(jl_typemap_entry_t*) *pml, jl_value_t *parent,
+        jl_typemap_t *map, _JAtomic(jl_typemap_entry_t*) *pml, jl_value_t *parent,
         jl_typemap_entry_t *newrec)
 {
     jl_typemap_entry_t *l = jl_atomic_load_relaxed(pml);
@@ -1140,7 +1140,7 @@ static void jl_typemap_list_insert_(
 }
 
 static void jl_typemap_insert_generic(
-        jl_typemap_t *map, _Atomic(jl_typemap_t*) *pml, jl_value_t *parent,
+        jl_typemap_t *map, _JAtomic(jl_typemap_t*) *pml, jl_value_t *parent,
         jl_typemap_entry_t *newrec, int8_t offs)
 {
     jl_typemap_t *ml = jl_atomic_load_relaxed(pml);
@@ -1159,16 +1159,16 @@ static void jl_typemap_insert_generic(
         return;
     }
 
-    jl_typemap_list_insert_(map, (_Atomic(jl_typemap_entry_t*)*)pml,
+    jl_typemap_list_insert_(map, (_JAtomic(jl_typemap_entry_t*)*)pml,
         parent, newrec);
 }
 
 static void jl_typemap_array_insert_(
-        jl_typemap_t *map, _Atomic(jl_array_t*) *pcache, jl_value_t *key, jl_typemap_entry_t *newrec,
+        jl_typemap_t *map, _JAtomic(jl_array_t*) *pcache, jl_value_t *key, jl_typemap_entry_t *newrec,
         jl_value_t *parent, int8_t offs)
 {
     jl_array_t *cache = jl_atomic_load_relaxed(pcache);
-    _Atomic(jl_typemap_t*) *pml = mtcache_hash_lookup_bp(cache, key);
+    _JAtomic(jl_typemap_t*) *pml = mtcache_hash_lookup_bp(cache, key);
     if (pml != NULL)
         jl_typemap_insert_generic(map, pml, (jl_value_t*)cache, newrec, offs+1);
     else
@@ -1286,7 +1286,7 @@ jl_typemap_entry_t *jl_typemap_alloc(
     return newrec;
 }
 
-void jl_typemap_insert(_Atomic(jl_typemap_t *) *pcache, jl_value_t *parent,
+void jl_typemap_insert(_JAtomic(jl_typemap_t *) *pcache, jl_value_t *parent,
         jl_typemap_entry_t *newrec, int8_t offs)
 {
     jl_typemap_t *cache = jl_atomic_load_relaxed(pcache);
diff --git a/src/win32_ucontext.c b/src/win32_ucontext.c
index c6d437230..8aced1102 100644
--- a/src/win32_ucontext.c
+++ b/src/win32_ucontext.c
@@ -3,6 +3,7 @@
 #include "win32_ucontext.h"
 
 #define WIN32_LEAN_AND_MEAN
+#define NOMINMAX
 #include <windows.h>
 
 #ifdef __cplusplus
diff --git a/test/clangsa/ImplicitAtomicsTest.c b/test/clangsa/ImplicitAtomicsTest.c
index 87154347d..f29b86bc5 100644
--- a/test/clangsa/ImplicitAtomicsTest.c
+++ b/test/clangsa/ImplicitAtomicsTest.c
@@ -5,13 +5,13 @@
 
 #include "julia_atomics.h"
 
-_Atomic(int) x, *px;
+_JAtomic(int) x, *px;
 struct Atomic_xy_t {
-    _Atomic(int) x;
-    _Atomic(int) *px;
+    _JAtomic(int) x;
+    _JAtomic(int) *px;
     int y;
 } y, *py;
-_Atomic(int) z[2];
+_JAtomic(int) z[2];
 
 
 // jwn: add tests for casts, and *py = y;
@@ -68,8 +68,8 @@ void hiddenAtomics(void) {
     y = // TODO
        *py; // TODO
 #endif
-    *(_Atomic(int)*)&y.y = 2; // CHECK: [[@LINE]]:22: warning: Implicit Atomic seq_cst synchronization
-    *(_Atomic(int)*)&py->y = 2; // CHECK: [[@LINE]]:22: warning: Implicit Atomic seq_cst synchronization
+    *(_JAtomic(int)*)&y.y = 2; // CHECK: [[@LINE]]:22: warning: Implicit Atomic seq_cst synchronization
+    *(_JAtomic(int)*)&py->y = 2; // CHECK: [[@LINE]]:22: warning: Implicit Atomic seq_cst synchronization
 
     y.x = 1; // CHECK: [[@LINE]]:5: warning: Implicit Atomic seq_cst synchronization
     *y.px = 1; // CHECK: [[@LINE]]:6: warning: Implicit Atomic seq_cst synchronization
@@ -90,7 +90,7 @@ void hiddenAtomics(void) {
 
 #ifdef __cplusplus // check initialization / finalization
     // CHECK-NOT: [[@LINE+1]]
-    _Atomic(int) lx{2};
+    _JAtomic(int) lx{2};
     lx = 3; // CHECK-CXX: [[@LINE]]:5: warning: Implicit Atomic seq_cst synchronization
     lx += 1; // CHECK-CXX: [[@LINE]]:5: warning: Implicit Atomic seq_cst synchronization
 
